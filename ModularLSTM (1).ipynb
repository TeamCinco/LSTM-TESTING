{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I-pSkYXq5qU"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOF0FYChq5qV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pickle\n",
        "import gc\n",
        "import time\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _delete_model(model):\n",
        "    \"\"\"Deletes the provided model\"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    del model"
      ],
      "metadata": {
        "id": "YohLOdtVEGpV"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P9FB_XWpuKv_"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umcZGjdaVRQy"
      },
      "source": [
        "# cuda implementation for faster processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lyEh-O7DVQUJ",
        "outputId": "a00d8b47-d11b-4d66-dfb1-3b8471f254ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512,expandable_segments:True'\n",
        "\n",
        "# Check CUDA availability and set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Memory status function\n",
        "def print_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"Memory allocated: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
        "        print(f\"Memory cached: {torch.cuda.memory_cached()/1e9:.2f} GB\")\n",
        "        print(f\"Max memory allocated: {torch.cuda.max_memory_allocated()/1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVVbe5PTq5qV"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "zW56Gpo_q5qW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "\n",
        "def check_gpu_memory():\n",
        "    \"\"\"Monitor GPU memory usage\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"No GPU available!\")\n",
        "        return None\n",
        "\n",
        "    total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "    reserved = torch.cuda.memory_reserved(0) / (1024**3)\n",
        "    allocated = torch.cuda.memory_allocated(0) / (1024**3)\n",
        "    free = total - reserved\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"GPU Memory Status ({torch.cuda.get_device_name(0)})\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Total GPU Memory:     {total:.2f} GB\")\n",
        "    print(f\"Reserved Memory:      {reserved:.2f} GB\")\n",
        "    print(f\"Allocated Memory:     {allocated:.2f} GB\")\n",
        "    print(f\"Free Memory:          {free:.2f} GB\")\n",
        "    print(f\"Memory Utilization:   {(reserved/total)*100:.1f}%\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    return {\n",
        "        \"total\": round(total, 2),\n",
        "        \"reserved\": round(reserved, 2),\n",
        "        \"allocated\": round(allocated, 2),\n",
        "        \"free\": round(free, 2),\n",
        "        \"utilization\": round((reserved/total)*100, 1)\n",
        "    }\n",
        "\n",
        "class Config:\n",
        "    # GPU Memory Management\n",
        "    TOTAL_GPU_MEMORY = 39.56  # GB (from your output)\n",
        "    MEMORY_RESERVE = 1.0      # GB (safety buffer)\n",
        "\n",
        "    # Date ranges\n",
        "    TRAIN_START_DATE = \"2018-05-02T08:44:39.292059872Z\"\n",
        "    TRAIN_END_DATE = \"2018-06-25T08:03:24.466039977Z\"\n",
        "    TEST_START_DATE = \"2018-06-25T08:03:24.466039977Z\"\n",
        "    TEST_END_DATE = \"2018-06-28T23:56:46.421875446Z\"\n",
        "\n",
        "    # Data files\n",
        "    RESULTS_DIR = '/content/results'\n",
        "    DATA_DIR = '/content/test'\n",
        "    FILE_PREFIX = \"xnas.itch_NVDA_\"\n",
        "    FILE_SUFFIX = \".csv\"\n",
        "\n",
        "    # Model Parameters\n",
        "    BATCH_SIZE = 1000\n",
        "    HIDDEN_SIZE = 256\n",
        "    NUM_LAYERS = 4\n",
        "    SEQUENCE_LENGTH = 1000\n",
        "    PREDICTION_LENGTH = 300\n",
        "\n",
        "    # Training Hyperparameters\n",
        "    LEARNING_RATE = 0.0001\n",
        "    EPOCHS = 100\n",
        "    WARMUP_EPOCHS = 5\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    GRADIENT_CLIP = 1.0\n",
        "\n",
        "    # Performance Optimizations\n",
        "    USE_AMP = True\n",
        "    NUM_WORKERS = 0\n",
        "    PIN_MEMORY = True\n",
        "    PREFETCH_FACTOR = 2\n",
        "    PERSISTENT_WORKERS = True\n",
        "    GRADIENT_ACCUMULATION_STEPS = 1\n",
        "    @classmethod\n",
        "    def initialize(cls):\n",
        "        \"\"\"Initialize and validate configuration\"\"\"\n",
        "        # Create directories\n",
        "        os.makedirs(cls.RESULTS_DIR, exist_ok=True)\n",
        "        os.makedirs(cls.DATA_DIR, exist_ok=True)\n",
        "\n",
        "        # Initialize CUDA\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()  # Clear cache\n",
        "            torch.cuda.set_device(0)  # Set primary GPU\n",
        "\n",
        "            # Enable TF32 for A100 (faster with minimal precision loss)\n",
        "            torch.backends.cuda.matmul.allow_tf32 = True\n",
        "            torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "            # Set memory fraction\n",
        "            usable_memory = (cls.TOTAL_GPU_MEMORY - cls.MEMORY_RESERVE) / cls.TOTAL_GPU_MEMORY\n",
        "            torch.cuda.set_per_process_memory_fraction(usable_memory)\n",
        "\n",
        "            # Print configuration\n",
        "            print(\"\\nModel Configuration:\")\n",
        "            print(f\"Batch Size: {cls.BATCH_SIZE}\")\n",
        "            print(f\"Hidden Size: {cls.HIDDEN_SIZE}\")\n",
        "            print(f\"Number of Layers: {cls.NUM_LAYERS}\")\n",
        "            print(f\"Sequence Length: {cls.SEQUENCE_LENGTH}\")\n",
        "            print(f\"Learning Rate: {cls.LEARNING_RATE}\")\n",
        "            print(f\"Using AMP: {cls.USE_AMP}\")\n",
        "            print(f\"Number of Workers: {cls.NUM_WORKERS}\")\n",
        "\n",
        "            # Check memory usage\n",
        "            memory_stats = check_gpu_memory()\n",
        "\n",
        "            # Calculate theoretical model size\n",
        "            model_size = cls.calculate_model_size()\n",
        "            print(f\"\\nEstimated Model Size: {model_size:.2f} GB\")\n",
        "\n",
        "            if model_size > (cls.TOTAL_GPU_MEMORY - cls.MEMORY_RESERVE):\n",
        "                print(\"\\nWarning: Model might be too large for GPU memory!\")\n",
        "                return False\n",
        "\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def calculate_model_size(cls):\n",
        "        \"\"\"Calculate approximate model memory usage in GB\"\"\"\n",
        "        # LSTM parameters\n",
        "        lstm_params = 4 * cls.HIDDEN_SIZE * (cls.HIDDEN_SIZE + 1) * cls.NUM_LAYERS\n",
        "\n",
        "        # Linear layer parameters\n",
        "        linear_params = cls.HIDDEN_SIZE * 1\n",
        "\n",
        "        # Total parameters\n",
        "        total_params = lstm_params + linear_params\n",
        "\n",
        "        # Memory calculations (in bytes)\n",
        "        param_memory = total_params * (2 if cls.USE_AMP else 4)  # Parameters\n",
        "        optimizer_memory = total_params * 8  # Adam optimizer states\n",
        "\n",
        "        # Batch memory\n",
        "        batch_memory = (cls.BATCH_SIZE * cls.SEQUENCE_LENGTH *\n",
        "                       cls.HIDDEN_SIZE * cls.NUM_LAYERS * 4)\n",
        "\n",
        "        # Convert to GB\n",
        "        total_memory = (param_memory + optimizer_memory + batch_memory) / (1024**3)\n",
        "\n",
        "        return total_memory\n",
        "\n",
        "    @classmethod\n",
        "    def get_dataloader_kwargs(cls):\n",
        "        \"\"\"Get optimized DataLoader settings\"\"\"\n",
        "        return {\n",
        "            'batch_size': cls.BATCH_SIZE,\n",
        "            'num_workers': cls.NUM_WORKERS,\n",
        "            'pin_memory': cls.PIN_MEMORY,\n",
        "            'prefetch_factor': cls.PREFETCH_FACTOR,\n",
        "            'persistent_workers': cls.PERSISTENT_WORKERS,\n",
        "            'drop_last': True\n",
        "        }\n",
        "\n",
        "    @classmethod\n",
        "    def validate(cls):\n",
        "        \"\"\"Validate configuration settings\"\"\"\n",
        "        model_size = cls.get_model_size()\n",
        "        available_memory = cls.GPU_MEMORY - cls.MEMORY_RESERVE\n",
        "\n",
        "        if model_size > available_memory:\n",
        "            print(f\"\\nWarning: Estimated model memory ({model_size:.1f} GB) exceeds available GPU memory ({available_memory:.1f} GB)\")\n",
        "            print(\"Suggestions:\")\n",
        "            print(\"1. Reduce BATCH_SIZE\")\n",
        "            print(\"2. Reduce HIDDEN_SIZE\")\n",
        "            print(\"3. Reduce NUM_LAYERS\")\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    @classmethod\n",
        "    def get_training_info(cls):\n",
        "        \"\"\"Get training configuration information\"\"\"\n",
        "        model_size_gb = cls.get_model_size()\n",
        "        batch_memory_gb = (cls.BATCH_SIZE * cls.SEQUENCE_LENGTH * 4) / (1024**3)\n",
        "\n",
        "        print(\"\\nTraining Configuration:\")\n",
        "        print(f\"Estimated model size: {model_size_gb:.2f} GB\")\n",
        "        print(f\"Estimated batch memory: {batch_memory_gb:.2f} GB\")\n",
        "        print(f\"Using Automatic Mixed Precision: {cls.USE_AMP}\")\n",
        "        print(f\"Batch size: {cls.BATCH_SIZE}\")\n",
        "        print(f\"Hidden size: {cls.HIDDEN_SIZE}\")\n",
        "        print(f\"Number of layers: {cls.NUM_LAYERS}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def validate_dates(cls):\n",
        "        try:\n",
        "            train_start = pd.to_datetime(cls.TRAIN_START_DATE, utc=True)\n",
        "            train_end = pd.to_datetime(cls.TRAIN_END_DATE, utc=True)\n",
        "            test_start = pd.to_datetime(cls.TEST_START_DATE, utc=True)\n",
        "            test_end = pd.to_datetime(cls.TEST_END_DATE, utc=True)\n",
        "\n",
        "            print(f\"\\nValidating date ranges:\")\n",
        "            print(f\"Train period: {train_start} to {train_end}\")\n",
        "            print(f\"Test period: {test_start} to {test_end}\")\n",
        "\n",
        "            assert train_start < train_end, \"Training start date must be before training end date\"\n",
        "            assert test_start < test_end, \"Test start date must be before test end date\"\n",
        "            assert train_end <= test_start, \"Training end date should be before or equal to test start date\"\n",
        "\n",
        "            # Adjust test_start if it's equal to train_end\n",
        "            if train_end == test_start:\n",
        "                cls.TEST_START_DATE = (test_start + pd.Timedelta(microseconds=1)).isoformat()\n",
        "                print(f\"Adjusted test start date to: {cls.TEST_START_DATE}\")\n",
        "\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Date validation error: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    @classmethod\n",
        "    def analyze_time_series(cls):\n",
        "        try:\n",
        "            all_diffs = []\n",
        "            csv_files = glob.glob(str(Path(cls.DATA_DIR) / \"*.csv\"))\n",
        "\n",
        "            for file in csv_files:\n",
        "                df = pd.read_csv(file)\n",
        "                df['ts_event'] = pd.to_datetime(df['ts_event'])\n",
        "                df = df.sort_values('ts_event')\n",
        "                time_diffs = df['ts_event'].diff().dt.total_seconds()\n",
        "                all_diffs.extend(time_diffs.dropna().tolist())\n",
        "\n",
        "            if not all_diffs:\n",
        "                raise ValueError(\"No valid time differences found in the data\")\n",
        "\n",
        "            median_diff = np.median(all_diffs)\n",
        "            mean_diff = np.mean(all_diffs)\n",
        "            std_diff = np.std(all_diffs)\n",
        "\n",
        "            typical_observations_per_30min = int((30 * 60) / median_diff)\n",
        "            cls.SEQUENCE_LENGTH = min(max(typical_observations_per_30min, 10), 100)\n",
        "\n",
        "            typical_observations_per_5min = int((5 * 60) / median_diff)\n",
        "            cls.PREDICTION_LENGTH = min(max(typical_observations_per_5min, 5), 30)\n",
        "\n",
        "            print(f\"\\nTime Series Analysis Results:\")\n",
        "            print(f\"Median time between observations: {median_diff:.2f} seconds\")\n",
        "            print(f\"Mean time between observations: {mean_diff:.2f} seconds\")\n",
        "            print(f\"Standard deviation: {std_diff:.2f} seconds\")\n",
        "            print(f\"Selected sequence length: {cls.SEQUENCE_LENGTH} observations\")\n",
        "            print(f\"Selected prediction length: {cls.PREDICTION_LENGTH} observations\")\n",
        "\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing time series: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    @classmethod\n",
        "    def get_file_list(cls):\n",
        "        start_date = pd.to_datetime(cls.TRAIN_START_DATE).date()\n",
        "        end_date = pd.to_datetime(cls.TEST_END_DATE).date()\n",
        "        date_range = pd.date_range(start_date, end_date)\n",
        "\n",
        "        file_list = []\n",
        "        for date in date_range:\n",
        "            file_name = f\"{cls.FILE_PREFIX}{date.strftime('%Y%m%d')}_to_{(date + timedelta(days=1)).strftime('%Y%m%d')}{cls.FILE_SUFFIX}\"\n",
        "            file_path = os.path.join(cls.DATA_DIR, file_name)\n",
        "            if os.path.exists(file_path):\n",
        "                file_list.append(file_path)\n",
        "\n",
        "        return file_list\n",
        "\n",
        "    @classmethod\n",
        "    def initialize(cls):\n",
        "        if not cls.validate_dates():\n",
        "            raise ValueError(\"Date validation failed\")\n",
        "        if not cls.analyze_time_series():\n",
        "            print(\"Warning: Using default sequence and prediction lengths\")\n",
        "        return True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-znhrGUq5qW"
      },
      "source": [
        "# Data Loading Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "OZ8BSf8Yq5qX"
      },
      "outputs": [],
      "source": [
        "def load_csv_data(file_list, columns=['ts_event', 'price']):\n",
        "    dfs = []\n",
        "    for file in file_list:\n",
        "        df = pd.read_csv(file, usecols=columns)\n",
        "        dfs.append(df)\n",
        "\n",
        "    df = pd.concat(dfs, ignore_index=True)\n",
        "    df['ts_event'] = pd.to_datetime(df['ts_event'], utc=True)\n",
        "    return df.sort_values('ts_event')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "6rpS9_EqhfNx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "hSJS7Tq-q5qX"
      },
      "outputs": [],
      "source": [
        "def run_with_progress():\n",
        "    # Initialize config\n",
        "    Config.initialize()\n",
        "\n",
        "    # Get file list\n",
        "    file_list = Config.get_file_list()\n",
        "\n",
        "    # Load data\n",
        "    print(\"Loading data...\")\n",
        "    df = load_csv_data(file_list)\n",
        "\n",
        "    # Preprocess data\n",
        "    print(\"Preprocessing data...\")\n",
        "    train_start = pd.to_datetime(Config.TRAIN_START_DATE, utc=True)\n",
        "    train_end = pd.to_datetime(Config.TRAIN_END_DATE, utc=True)\n",
        "    test_start = pd.to_datetime(Config.TEST_START_DATE, utc=True)\n",
        "    test_end = pd.to_datetime(Config.TEST_END_DATE, utc=True)\n",
        "\n",
        "    X_train, y_train, X_test, y_test, scaler, test_df = preprocess_data(\n",
        "        df, train_start, train_end, test_start, test_end, Config.SEQUENCE_LENGTH\n",
        "    )\n",
        "\n",
        "    # Create dataset and dataloader for training data\n",
        "    train_dataset = PriceDataset(X_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=Config.NUM_WORKERS)\n",
        "\n",
        "    # Initialize model, loss function, and optimizer\n",
        "    model = LSTMModel(hidden_size=Config.HIDDEN_SIZE, num_layers=Config.NUM_LAYERS)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)\n",
        "\n",
        "    # Train the model\n",
        "    print(\"Training model...\")\n",
        "    train_model_with_progress(model, train_loader, criterion, optimizer)\n",
        "\n",
        "    # Make predictions on test data\n",
        "    print(\"Making predictions...\")\n",
        "    test_predictions = predict_with_progress(model, X_test, scaler)\n",
        "\n",
        "    # Create a DataFrame with test predictions\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'ts_event': test_df['ts_event'][Config.SEQUENCE_LENGTH:].reset_index(drop=True),\n",
        "        'predicted_price': test_predictions,\n",
        "        'actual_price': test_df['price'][Config.SEQUENCE_LENGTH:].reset_index(drop=True)\n",
        "    })\n",
        "\n",
        "    # Plot predicted vs actual prices\n",
        "    plot_predicted_vs_actual(predictions_df)\n",
        "\n",
        "    print(predictions_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syyVLngbq5qX"
      },
      "source": [
        "# Data Preprocessing Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "VOUMeCNbq5qX"
      },
      "outputs": [],
      "source": [
        "    def preprocess_data(self, df, train_start, train_end, test_start, test_end, sequence_length):\n",
        "        \"\"\"Preprocess data keeping larger datasets in CPU memory\"\"\"\n",
        "        # Split data into train/test on CPU\n",
        "        train_mask = (df['ts_event'] >= train_start) & (df['ts_event'] < train_end)\n",
        "        test_mask = (df['ts_event'] >= test_start) & (df['ts_event'] <= test_end)\n",
        "\n",
        "        train_df = df[train_mask]\n",
        "        test_df = df[test_mask]\n",
        "\n",
        "        # Scale data on CPU\n",
        "        scaler = MinMaxScaler()\n",
        "        train_prices = scaler.fit_transform(train_df['price'].values.reshape(-1, 1))\n",
        "        test_prices = scaler.transform(test_df['price'].values.reshape(-1, 1))\n",
        "\n",
        "        # Create sequences staying on CPU initially\n",
        "        X_train, y_train = self._create_sequences(train_prices, sequence_length)\n",
        "        X_test, y_test = self._create_sequences(test_prices, sequence_length)\n",
        "\n",
        "        return X_train, y_train, X_test, y_test, scaler, test_df\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_sequences(data, sequence_length):\n",
        "        \"\"\"Create sequences in CPU memory\"\"\"\n",
        "        X, y = [], []\n",
        "        for i in range(len(data) - sequence_length):\n",
        "            X.append(data[i:i+sequence_length])\n",
        "            y.append(data[i+sequence_length])\n",
        "        return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "TdUlWpCiiK-m"
      },
      "outputs": [],
      "source": [
        "class DataManager:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "    def load_data(self, file_list, columns=['ts_event', 'price']):\n",
        "        \"\"\"Load data into CPU RAM\"\"\"\n",
        "        # Load data in chunks to manage memory\n",
        "        chunk_size = 1000000  # Adjust based on your RAM\n",
        "        dfs = []\n",
        "        for file in file_list:\n",
        "            # Read CSV in chunks to control memory usage\n",
        "            for chunk in pd.read_csv(file, usecols=columns, chunksize=chunk_size):\n",
        "                dfs.append(chunk)\n",
        "\n",
        "        df = pd.concat(dfs, ignore_index=True)\n",
        "        df['ts_event'] = pd.to_datetime(df['ts_event'], utc=True)\n",
        "        return df.sort_values('ts_event')\n",
        "\n",
        "    def preprocess_data(self, df, train_start, train_end, test_start, test_end, sequence_length):\n",
        "        \"\"\"Preprocess data keeping larger datasets in CPU memory\"\"\"\n",
        "        # Split data into train/test on CPU\n",
        "        train_mask = (df['ts_event'] >= train_start) & (df['ts_event'] < train_end)\n",
        "        test_mask = (df['ts_event'] >= test_start) & (df['ts_event'] <= test_end)\n",
        "\n",
        "        train_df = df[train_mask]\n",
        "        test_df = df[test_mask]\n",
        "\n",
        "        # Scale data on CPU\n",
        "        scaler = MinMaxScaler()\n",
        "        train_prices = scaler.fit_transform(train_df['price'].values.reshape(-1, 1))\n",
        "        test_prices = scaler.transform(test_df['price'].values.reshape(-1, 1))\n",
        "\n",
        "        # Create sequences staying on CPU initially\n",
        "        X_train, y_train = self.create_sequences(train_prices, sequence_length)\n",
        "        X_test, y_test = self.create_sequences(test_prices, sequence_length)\n",
        "\n",
        "        return X_train, y_train, X_test, y_test, scaler, test_df\n",
        "\n",
        "    def create_sequences(self, data, sequence_length):\n",
        "        \"\"\"\n",
        "        Create sequences for time series prediction.\n",
        "\n",
        "        Args:\n",
        "            data (numpy.ndarray): Input data array\n",
        "            sequence_length (int): Length of each sequence\n",
        "\n",
        "        Returns:\n",
        "            tuple: Arrays of input sequences and target values\n",
        "        \"\"\"\n",
        "        X, y = [], []\n",
        "\n",
        "        # Process data in chunks to manage memory\n",
        "        chunk_size = 10000\n",
        "        total_sequences = len(data) - sequence_length\n",
        "\n",
        "        for i in range(0, total_sequences, chunk_size):\n",
        "            end_idx = min(i + chunk_size, total_sequences)\n",
        "\n",
        "            # Create sequences for this chunk\n",
        "            for j in range(i, end_idx):\n",
        "                X.append(data[j:j+sequence_length])\n",
        "                y.append(data[j+sequence_length])\n",
        "\n",
        "            # Optional: Free memory if needed\n",
        "            if i % (chunk_size * 10) == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "class BatchManager:\n",
        "    def __init__(self, X, y, batch_size):\n",
        "        \"\"\"\n",
        "        Initialize batch manager for memory-efficient training\n",
        "\n",
        "        Args:\n",
        "            X (numpy.ndarray): Input sequences\n",
        "            y (numpy.ndarray): Target values\n",
        "            batch_size (int): Size of each batch\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "        self.n_samples = len(X)\n",
        "        self.current_idx = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.current_idx = 0\n",
        "        # Create random indices for shuffling\n",
        "        self.indices = np.random.permutation(self.n_samples)\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.current_idx >= self.n_samples:\n",
        "            raise StopIteration\n",
        "\n",
        "        end_idx = min(self.current_idx + self.batch_size, self.n_samples)\n",
        "        batch_indices = self.indices[self.current_idx:end_idx]\n",
        "\n",
        "        # Move batch to GPU only when needed\n",
        "        X_batch = torch.FloatTensor(self.X[batch_indices]).to(device)\n",
        "        y_batch = torch.FloatTensor(self.y[batch_indices]).to(device)\n",
        "\n",
        "        self.current_idx = end_idx\n",
        "        return X_batch, y_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smlaC4vfq5qX"
      },
      "source": [
        "# Custom Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "qQNwqLl8q5qY"
      },
      "outputs": [],
      "source": [
        "class PriceDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.FloatTensor(X).to(device)\n",
        "        self.y = torch.FloatTensor(y).to(device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvbmj_qiq5qY"
      },
      "source": [
        "# LSTM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "j2rDBFeTq5qY"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=32, num_layers=1):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Move states to same device as input\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward pass\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "    def save_model(self, path, optimizer=None, epoch=None, loss=None):\n",
        "        \"\"\"Save model state, optimizer state, and training info\"\"\"\n",
        "        checkpoint = {\n",
        "            'model_state_dict': self.state_dict(),\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_layers': self.num_layers\n",
        "        }\n",
        "\n",
        "        if optimizer is not None:\n",
        "            checkpoint['optimizer_state_dict'] = optimizer.state_dict()\n",
        "        if epoch is not None:\n",
        "            checkpoint['epoch'] = epoch\n",
        "        if loss is not None:\n",
        "            checkpoint['loss'] = loss\n",
        "\n",
        "        torch.save(checkpoint, path)\n",
        "\n",
        "    @classmethod\n",
        "    def load_model(cls, path, device='cuda'):\n",
        "        \"\"\"Load a saved model\"\"\"\n",
        "        checkpoint = torch.load(path, map_location=device)\n",
        "\n",
        "        model = cls(\n",
        "            hidden_size=checkpoint['hidden_size'],\n",
        "            num_layers=checkpoint['num_layers']\n",
        "        )\n",
        "\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model = model.to(device)\n",
        "\n",
        "        return model, checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MemoryOptimizedDataset(Dataset):\n",
        "    def __init__(self, data_dir, start_date, end_date, sequence_length, prediction_length):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.prediction_length = prediction_length\n",
        "        self.data = self.load_data(data_dir, start_date, end_date)\n",
        "\n",
        "    def load_data(self, data_dir, start_date, end_date):\n",
        "        # Load data in chunks to avoid memory issues\n",
        "        chunks = []\n",
        "        for file in sorted(Path(data_dir).glob(f\"{Config.FILE_PREFIX}*{Config.FILE_SUFFIX}\")):\n",
        "            try:\n",
        "                chunk = pd.read_csv(file, parse_dates=['timestamp'])\n",
        "                if chunk['timestamp'].min() <= end_date and chunk['timestamp'].max() >= start_date:\n",
        "                    chunks.append(chunk)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file}: {e}\")\n",
        "\n",
        "        data = pd.concat(chunks, ignore_index=True)\n",
        "        data = data[(data['timestamp'] >= start_date) & (data['timestamp'] <= end_date)]\n",
        "        return data.values  # Convert to numpy for memory efficiency\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(0, len(self.data) - self.sequence_length - self.prediction_length)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = self.data[idx:idx + self.sequence_length]\n",
        "        target = self.data[idx + self.sequence_length:idx + self.sequence_length + self.prediction_length]\n",
        "        return torch.FloatTensor(sequence), torch.FloatTensor(target)\n",
        "\n",
        "class MemoryOptimizedModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, sequence_length, prediction_length):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Memory-efficient architecture\n",
        "        self.input_projection = nn.Linear(input_size, hidden_size)\n",
        "        self.lstm_layers = nn.ModuleList([\n",
        "            nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.output_projection = nn.Linear(hidden_size, prediction_length)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input projection\n",
        "        x = self.input_projection(x)\n",
        "\n",
        "        # Process LSTM layers with checkpointing\n",
        "        for lstm in self.lstm_layers:\n",
        "            x, _ = lstm(x)\n",
        "            x = self.layer_norm(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        # Output projection\n",
        "        x = self.output_projection(x[:, -1])\n",
        "        return x\n",
        "\n",
        "def setup_memory_optimization():\n",
        "    \"\"\"Setup memory optimization configurations\"\"\"\n",
        "    # Set PyTorch memory allocator settings\n",
        "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
        "\n",
        "    # Enable CUDA memory optimization\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        # Calculate maximum batch size based on available memory\n",
        "        available_memory = Config.TOTAL_GPU_MEMORY - Config.MEMORY_RESERVE\n",
        "        print(f\"Available GPU memory: {available_memory:.2f} GB\")\n",
        "\n",
        "        # Set CUDA memory optimization flags\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True"
      ],
      "metadata": {
        "id": "J-SdVfcBw8Wt"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALsEVDN-q5qY"
      },
      "source": [
        "# Training Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "z9BX67wlq5qY"
      },
      "outputs": [],
      "source": [
        "def train_model():\n",
        "    \"\"\"Main training function with memory optimization\"\"\"\n",
        "    setup_memory_optimization()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Initialize datasets\n",
        "    train_dataset = MemoryOptimizedDataset(\n",
        "        Config.DATA_DIR,\n",
        "        Config.TRAIN_START_DATE,\n",
        "        Config.TRAIN_END_DATE,\n",
        "        Config.SEQUENCE_LENGTH,\n",
        "        Config.PREDICTION_LENGTH\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=Config.BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=Config.NUM_WORKERS,\n",
        "        pin_memory=Config.PIN_MEMORY,\n",
        "        prefetch_factor=Config.PREFETCH_FACTOR,\n",
        "        persistent_workers=Config.PERSISTENT_WORKERS\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    input_size = train_dataset.data.shape[1]\n",
        "    model = MemoryOptimizedModel(\n",
        "        input_size=input_size,\n",
        "        hidden_size=Config.HIDDEN_SIZE,\n",
        "        num_layers=Config.NUM_LAYERS,\n",
        "        sequence_length=Config.SEQUENCE_LENGTH,\n",
        "        prediction_length=Config.PREDICTION_LENGTH\n",
        "    ).to(device)\n",
        "\n",
        "    # Initialize optimizer and scheduler\n",
        "    optimizer = optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=Config.LEARNING_RATE,\n",
        "        weight_decay=Config.WEIGHT_DECAY\n",
        "    )\n",
        "\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=Config.LEARNING_RATE,\n",
        "        epochs=Config.EPOCHS,\n",
        "        steps_per_epoch=len(train_loader)\n",
        "    )\n",
        "\n",
        "    # Initialize AMP scaler\n",
        "    scaler = GradScaler(enabled=Config.USE_AMP)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(Config.EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        with tqdm(train_loader, desc=f'Epoch {epoch+1}/{Config.EPOCHS}') as pbar:\n",
        "            for batch_idx, (data, target) in enumerate(pbar):\n",
        "                data, target = data.to(device), target.to(device)\n",
        "\n",
        "                # Clear gradients and cache\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "                # Forward pass with AMP\n",
        "                with autocast(enabled=Config.USE_AMP):\n",
        "                    output = model(data)\n",
        "                    loss = F.mse_loss(output, target)\n",
        "\n",
        "                # Backward pass with gradient scaling\n",
        "                scaler.scale(loss).backward()\n",
        "\n",
        "                # Gradient clipping\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), Config.GRADIENT_CLIP)\n",
        "\n",
        "                # Optimizer step with scaling\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "                # Scheduler step\n",
        "                scheduler.step()\n",
        "\n",
        "                # Update progress bar\n",
        "                total_loss += loss.item()\n",
        "                pbar.set_postfix({'loss': total_loss / (batch_idx + 1)})\n",
        "\n",
        "                # Memory cleanup\n",
        "                if batch_idx % 10 == 0:\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            checkpoint_path = Path(Config.RESULTS_DIR) / f'checkpoint_epoch_{epoch+1}.pt'\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': total_loss / len(train_loader),\n",
        "            }, checkpoint_path)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTf_SD3tq5qY"
      },
      "source": [
        "# Prediction Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "xJEk5gzSq5qY"
      },
      "outputs": [],
      "source": [
        "def predict_with_progress(model, X_test, scaler, batch_size=64):\n",
        "    \"\"\"Make predictions with batched CPU to GPU transfer\"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Process test data in batches\n",
        "        for i in range(0, len(X_test), batch_size):\n",
        "            batch = X_test[i:i+batch_size]\n",
        "            X = torch.FloatTensor(batch).to(device)\n",
        "            y_pred = model(X)\n",
        "            predictions.extend(scaler.inverse_transform(y_pred.cpu().numpy()))\n",
        "\n",
        "            # Clear GPU memory\n",
        "            del X, y_pred\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb7qSS3qq5qY"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "def visualize_predictions(predictions_df):\n",
        "    \"\"\"\n",
        "    Create comprehensive visualizations for price predictions\n",
        "\n",
        "    Args:\n",
        "        predictions_df: DataFrame with columns 'ts_event', 'actual_price', 'predicted_price'\n",
        "    \"\"\"\n",
        "    # Set style\n",
        "    plt.style.use('seaborn')\n",
        "\n",
        "    # Calculate error metrics\n",
        "    mse = mean_squared_error(predictions_df['actual_price'], predictions_df['predicted_price'])\n",
        "    mae = mean_absolute_error(predictions_df['actual_price'], predictions_df['predicted_price'])\n",
        "    r2 = r2_score(predictions_df['actual_price'], predictions_df['predicted_price'])\n",
        "\n",
        "    # Calculate percentage error\n",
        "    predictions_df['error'] = predictions_df['predicted_price'] - predictions_df['actual_price']\n",
        "    predictions_df['error_pct'] = (predictions_df['error'] / predictions_df['actual_price']) * 100\n",
        "\n",
        "    # Create subplots\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "    # 1. Price Comparison Plot\n",
        "    ax1 = plt.subplot(3, 1, 1)\n",
        "    ax1.plot(predictions_df['ts_event'], predictions_df['actual_price'], label='Actual Price', color='blue', alpha=0.7)\n",
        "    ax1.plot(predictions_df['ts_event'], predictions_df['predicted_price'], label='Predicted Price', color='red', alpha=0.7)\n",
        "    ax1.set_title('Actual vs Predicted Price Over Time', fontsize=14, pad=20)\n",
        "    ax1.set_xlabel('Time')\n",
        "    ax1.set_ylabel('Price')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Error Distribution\n",
        "    ax2 = plt.subplot(3, 2, 3)\n",
        "    sns.histplot(predictions_df['error'], bins=50, ax=ax2, color='blue', alpha=0.6)\n",
        "    ax2.set_title('Error Distribution', fontsize=12)\n",
        "    ax2.set_xlabel('Error (Predicted - Actual)')\n",
        "    ax2.set_ylabel('Count')\n",
        "\n",
        "    # 3. Percentage Error Distribution\n",
        "    ax3 = plt.subplot(3, 2, 4)\n",
        "    sns.histplot(predictions_df['error_pct'], bins=50, ax=ax3, color='green', alpha=0.6)\n",
        "    ax3.set_title('Percentage Error Distribution', fontsize=12)\n",
        "    ax3.set_xlabel('Percentage Error')\n",
        "    ax3.set_ylabel('Count')\n",
        "\n",
        "    # 4. Scatter Plot\n",
        "    ax4 = plt.subplot(3, 1, 3)\n",
        "    ax4.scatter(predictions_df['actual_price'], predictions_df['predicted_price'],\n",
        "               alpha=0.5, color='blue')\n",
        "\n",
        "    # Add perfect prediction line\n",
        "    min_val = min(predictions_df['actual_price'].min(), predictions_df['predicted_price'].min())\n",
        "    max_val = max(predictions_df['actual_price'].max(), predictions_df['predicted_price'].max())\n",
        "    ax4.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect Prediction')\n",
        "\n",
        "    ax4.set_title('Predicted vs Actual Prices', fontsize=12)\n",
        "    ax4.set_xlabel('Actual Price')\n",
        "    ax4.set_ylabel('Predicted Price')\n",
        "    ax4.legend()\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add text box with metrics\n",
        "    metrics_text = f'Mean Squared Error: {mse:.4f}\\nMean Absolute Error: {mae:.4f}\\nR² Score: {r2:.4f}'\n",
        "    plt.figtext(0.02, 0.02, metrics_text, fontsize=12,\n",
        "                bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "\n",
        "    # Add main title\n",
        "    plt.suptitle('Price Prediction Analysis', fontsize=16, y=0.98)\n",
        "\n",
        "    return fig\n",
        "\n",
        "def plot_error_analysis(predictions_df):\n",
        "    \"\"\"\n",
        "    Create detailed error analysis visualizations\n",
        "\n",
        "    Args:\n",
        "        predictions_df: DataFrame with columns 'ts_event', 'actual_price', 'predicted_price'\n",
        "    \"\"\"\n",
        "    # Calculate rolling metrics\n",
        "    window_size = 100\n",
        "    predictions_df['rolling_mse'] = (predictions_df['actual_price'] - predictions_df['predicted_price'])**2 \\\n",
        "                                   .rolling(window=window_size).mean()\n",
        "    predictions_df['rolling_mae'] = abs(predictions_df['actual_price'] - predictions_df['predicted_price']) \\\n",
        "                                   .rolling(window=window_size).mean()\n",
        "\n",
        "    # Create figure\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "\n",
        "    # 1. Rolling Error Metrics\n",
        "    ax1 = plt.subplot(2, 1, 1)\n",
        "    ax1.plot(predictions_df['ts_event'], predictions_df['rolling_mse'],\n",
        "             label=f'Rolling MSE (window={window_size})', color='red', alpha=0.7)\n",
        "    ax1.plot(predictions_df['ts_event'], predictions_df['rolling_mae'],\n",
        "             label=f'Rolling MAE (window={window_size})', color='blue', alpha=0.7)\n",
        "    ax1.set_title('Rolling Error Metrics Over Time', fontsize=14)\n",
        "    ax1.set_xlabel('Time')\n",
        "    ax1.set_ylabel('Error')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Error Heatmap\n",
        "    ax2 = plt.subplot(2, 1, 2)\n",
        "\n",
        "    # Create price bins\n",
        "    price_bins = pd.qcut(predictions_df['actual_price'], q=20)\n",
        "    error_by_price = predictions_df.groupby(price_bins)['error'].agg(['mean', 'std']).round(4)\n",
        "\n",
        "    sns.heatmap(error_by_price.T, annot=True, cmap='RdYlBu_r', ax=ax2, center=0)\n",
        "    ax2.set_title('Error Analysis by Price Range', fontsize=14)\n",
        "    ax2.set_xlabel('Price Range Percentile')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig"
      ],
      "metadata": {
        "id": "ti7Fr3QJ0sdz"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KVepLVxq5qY"
      },
      "source": [
        "# Main execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "qg4lIk80q5qZ"
      },
      "outputs": [],
      "source": [
        "def prepare_data(config):\n",
        "    \"\"\"Prepare data with memory optimization\"\"\"\n",
        "    print(\"Preparing data...\")\n",
        "    print_gpu_memory()\n",
        "\n",
        "    config.initialize()\n",
        "    file_list = config.get_file_list()\n",
        "\n",
        "    # Load and preprocess data in chunks if needed\n",
        "    df = load_csv_data(file_list)\n",
        "\n",
        "    train_start = pd.to_datetime(config.TRAIN_START_DATE, utc=True)\n",
        "    train_end = pd.to_datetime(config.TRAIN_END_DATE, utc=True)\n",
        "    test_start = pd.to_datetime(config.TEST_START_DATE, utc=True)\n",
        "    test_end = pd.to_datetime(config.TEST_END_DATE, utc=True)\n",
        "\n",
        "    X_train, y_train, X_test, y_test, scaler, test_df = preprocess_data(\n",
        "        df, train_start, train_end, test_start, test_end, config.SEQUENCE_LENGTH\n",
        "    )\n",
        "\n",
        "    # Clear memory\n",
        "    del df\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, scaler, test_df, (train_start, train_end, test_start, test_end)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "4LTST72hq5qZ"
      },
      "outputs": [],
      "source": [
        "def setup_training(X_train, y_train, config):\n",
        "    \"\"\"Setup training components including dataset, model and optimizer\"\"\"\n",
        "    # Create dataset and dataloader\n",
        "    train_dataset = PriceDataset(X_train, y_train)\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=config.NUM_WORKERS\n",
        "    )\n",
        "\n",
        "    # Initialize model, loss and optimizer\n",
        "    model = LSTMModel(hidden_size=config.HIDDEN_SIZE, num_layers=config.NUM_LAYERS).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "    return train_loader, model, criterion, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "XCtXqG0pq5qZ"
      },
      "outputs": [],
      "source": [
        "def train_and_predict(train_loader, model, criterion, optimizer, X_test, scaler, test_df, config):\n",
        "    \"\"\"Execute training and generate predictions\"\"\"\n",
        "    # Train the model\n",
        "    train_model_with_progress(model, train_loader, criterion, optimizer)\n",
        "\n",
        "    # Generate predictions\n",
        "    test_predictions = predict_with_progress(model, X_test, scaler)\n",
        "\n",
        "    # Create predictions dataframe\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'ts_event': test_df['ts_event'][config.SEQUENCE_LENGTH:].reset_index(drop=True),\n",
        "        'predicted_price': test_predictions,\n",
        "        'actual_price': test_df['price'][config.SEQUENCE_LENGTH:].reset_index(drop=True)\n",
        "    })\n",
        "\n",
        "    return predictions_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL-0Nkyvq5qZ",
        "outputId": "4ae3f427-45f8-4bd0-97f9-54b06167d036"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting pipeline...\n",
            "\n",
            "Epoch [1/100]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/452 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 1/452 [00:00<03:14,  2.32batch/s]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 1/452 [00:00<03:14,  2.32batch/s, Loss=0.3762, Batch=1/452]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 2/452 [00:01<05:00,  1.50batch/s, Loss=0.3762, Batch=1/452]\u001b[A\u001b[A\n",
            "\n",
            "  0%|          | 2/452 [00:01<05:00,  1.50batch/s, Loss=0.3772, Batch=2/452]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 3/452 [00:02<05:34,  1.34batch/s, Loss=0.3772, Batch=2/452]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 3/452 [00:02<05:34,  1.34batch/s, Loss=0.3708, Batch=3/452]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 4/452 [00:02<05:50,  1.28batch/s, Loss=0.3708, Batch=3/452]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 4/452 [00:02<05:50,  1.28batch/s, Loss=0.3660, Batch=4/452]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 5/452 [00:03<05:58,  1.25batch/s, Loss=0.3660, Batch=4/452]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 5/452 [00:03<05:58,  1.25batch/s, Loss=0.3619, Batch=5/452]\u001b[A\u001b[A\n",
            "\n",
            "  1%|▏         | 6/452 [00:04<06:03,  1.23batch/s, Loss=0.3619, Batch=5/452]\u001b[A\u001b[A\n",
            "\n",
            "  1%|▏         | 6/452 [00:04<06:03,  1.23batch/s, Loss=0.3567, Batch=6/452]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 7/452 [00:05<06:06,  1.21batch/s, Loss=0.3567, Batch=6/452]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 7/452 [00:05<06:06,  1.21batch/s, Loss=0.3507, Batch=7/452]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 8/452 [00:06<06:07,  1.21batch/s, Loss=0.3507, Batch=7/452]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 8/452 [00:06<06:07,  1.21batch/s, Loss=0.3459, Batch=8/452]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 9/452 [00:07<06:08,  1.20batch/s, Loss=0.3459, Batch=8/452]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 9/452 [00:07<06:08,  1.20batch/s, Loss=0.3401, Batch=9/452]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 10/452 [00:07<06:08,  1.20batch/s, Loss=0.3401, Batch=9/452]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 10/452 [00:07<06:08,  1.20batch/s, Loss=0.3353, Batch=10/452]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 11/452 [00:08<06:08,  1.20batch/s, Loss=0.3353, Batch=10/452]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 11/452 [00:08<06:08,  1.20batch/s, Loss=0.3302, Batch=11/452]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 12/452 [00:09<06:08,  1.19batch/s, Loss=0.3302, Batch=11/452]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 12/452 [00:09<06:08,  1.19batch/s, Loss=0.3245, Batch=12/452]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 13/452 [00:10<06:08,  1.19batch/s, Loss=0.3245, Batch=12/452]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 13/452 [00:10<06:08,  1.19batch/s, Loss=0.3194, Batch=13/452]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 14/452 [00:11<06:07,  1.19batch/s, Loss=0.3194, Batch=13/452]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 14/452 [00:11<06:07,  1.19batch/s, Loss=0.3145, Batch=14/452]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 15/452 [00:12<06:06,  1.19batch/s, Loss=0.3145, Batch=14/452]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 15/452 [00:12<06:06,  1.19batch/s, Loss=0.3089, Batch=15/452]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 16/452 [00:13<06:06,  1.19batch/s, Loss=0.3089, Batch=15/452]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▎         | 16/452 [00:13<06:06,  1.19batch/s, Loss=0.3031, Batch=16/452]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 17/452 [00:13<06:05,  1.19batch/s, Loss=0.3031, Batch=16/452]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 17/452 [00:13<06:05,  1.19batch/s, Loss=0.2969, Batch=17/452]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 18/452 [00:14<06:04,  1.19batch/s, Loss=0.2969, Batch=17/452]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 18/452 [00:14<06:04,  1.19batch/s, Loss=0.2910, Batch=18/452]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 19/452 [00:15<06:04,  1.19batch/s, Loss=0.2910, Batch=18/452]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 19/452 [00:15<06:04,  1.19batch/s, Loss=0.2852, Batch=19/452]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 20/452 [00:16<06:03,  1.19batch/s, Loss=0.2852, Batch=19/452]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 20/452 [00:16<06:03,  1.19batch/s, Loss=0.2792, Batch=20/452]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 21/452 [00:17<06:02,  1.19batch/s, Loss=0.2792, Batch=20/452]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 21/452 [00:17<06:02,  1.19batch/s, Loss=0.2730, Batch=21/452]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 22/452 [00:18<06:01,  1.19batch/s, Loss=0.2730, Batch=21/452]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▍         | 22/452 [00:18<06:01,  1.19batch/s, Loss=0.2667, Batch=22/452]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 23/452 [00:18<06:00,  1.19batch/s, Loss=0.2667, Batch=22/452]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 23/452 [00:18<06:00,  1.19batch/s, Loss=0.2602, Batch=23/452]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 24/452 [00:19<06:00,  1.19batch/s, Loss=0.2602, Batch=23/452]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 24/452 [00:19<06:00,  1.19batch/s, Loss=0.2537, Batch=24/452]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 25/452 [00:20<06:00,  1.19batch/s, Loss=0.2537, Batch=24/452]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 25/452 [00:20<06:00,  1.19batch/s, Loss=0.2469, Batch=25/452]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 26/452 [00:21<05:59,  1.19batch/s, Loss=0.2469, Batch=25/452]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 26/452 [00:21<05:59,  1.19batch/s, Loss=0.2402, Batch=26/452]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 27/452 [00:22<05:57,  1.19batch/s, Loss=0.2402, Batch=26/452]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 27/452 [00:22<05:57,  1.19batch/s, Loss=0.2336, Batch=27/452]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 28/452 [00:23<05:56,  1.19batch/s, Loss=0.2336, Batch=27/452]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▌         | 28/452 [00:23<05:56,  1.19batch/s, Loss=0.2273, Batch=28/452]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▋         | 29/452 [00:23<05:56,  1.19batch/s, Loss=0.2273, Batch=28/452]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▋         | 29/452 [00:23<05:56,  1.19batch/s, Loss=0.2213, Batch=29/452]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 30/452 [00:24<05:56,  1.19batch/s, Loss=0.2213, Batch=29/452]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 30/452 [00:24<05:56,  1.19batch/s, Loss=0.2162, Batch=30/452]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 31/452 [00:25<05:55,  1.18batch/s, Loss=0.2162, Batch=30/452]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 31/452 [00:25<05:55,  1.18batch/s, Loss=0.2121, Batch=31/452]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 32/452 [00:26<05:53,  1.19batch/s, Loss=0.2121, Batch=31/452]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 32/452 [00:26<05:53,  1.19batch/s, Loss=0.2082, Batch=32/452]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 33/452 [00:27<05:52,  1.19batch/s, Loss=0.2082, Batch=32/452]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 33/452 [00:27<05:52,  1.19batch/s, Loss=0.2041, Batch=33/452]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 34/452 [00:28<05:51,  1.19batch/s, Loss=0.2041, Batch=33/452]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 34/452 [00:28<05:51,  1.19batch/s, Loss=0.2001, Batch=34/452]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 35/452 [00:29<05:51,  1.19batch/s, Loss=0.2001, Batch=34/452]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 35/452 [00:29<05:51,  1.19batch/s, Loss=0.1960, Batch=35/452]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 36/452 [00:29<05:50,  1.19batch/s, Loss=0.1960, Batch=35/452]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 36/452 [00:29<05:50,  1.19batch/s, Loss=0.1922, Batch=36/452]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 37/452 [00:30<05:49,  1.19batch/s, Loss=0.1922, Batch=36/452]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 37/452 [00:30<05:49,  1.19batch/s, Loss=0.1883, Batch=37/452]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 38/452 [00:31<05:47,  1.19batch/s, Loss=0.1883, Batch=37/452]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 38/452 [00:31<05:47,  1.19batch/s, Loss=0.1848, Batch=38/452]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▊         | 39/452 [00:32<05:46,  1.19batch/s, Loss=0.1848, Batch=38/452]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▊         | 39/452 [00:32<05:46,  1.19batch/s, Loss=0.1815, Batch=39/452]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 40/452 [00:33<05:45,  1.19batch/s, Loss=0.1815, Batch=39/452]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 40/452 [00:33<05:45,  1.19batch/s, Loss=0.1785, Batch=40/452]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 41/452 [00:34<05:46,  1.19batch/s, Loss=0.1785, Batch=40/452]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 41/452 [00:34<05:46,  1.19batch/s, Loss=0.1755, Batch=41/452]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 42/452 [00:34<05:45,  1.19batch/s, Loss=0.1755, Batch=41/452]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▉         | 42/452 [00:34<05:45,  1.19batch/s, Loss=0.1727, Batch=42/452]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 43/452 [00:35<05:44,  1.19batch/s, Loss=0.1727, Batch=42/452]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 43/452 [00:35<05:44,  1.19batch/s, Loss=0.1700, Batch=43/452]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 44/452 [00:36<05:43,  1.19batch/s, Loss=0.1700, Batch=43/452]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 44/452 [00:36<05:43,  1.19batch/s, Loss=0.1676, Batch=44/452]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 45/452 [00:37<05:42,  1.19batch/s, Loss=0.1676, Batch=44/452]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 45/452 [00:37<05:42,  1.19batch/s, Loss=0.1652, Batch=45/452]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 46/452 [00:38<05:41,  1.19batch/s, Loss=0.1652, Batch=45/452]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 46/452 [00:38<05:41,  1.19batch/s, Loss=0.1629, Batch=46/452]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 47/452 [00:39<05:41,  1.19batch/s, Loss=0.1629, Batch=46/452]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 47/452 [00:39<05:41,  1.19batch/s, Loss=0.1606, Batch=47/452]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 48/452 [00:39<05:39,  1.19batch/s, Loss=0.1606, Batch=47/452]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 48/452 [00:39<05:39,  1.19batch/s, Loss=0.1584, Batch=48/452]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 49/452 [00:40<05:39,  1.19batch/s, Loss=0.1584, Batch=48/452]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 49/452 [00:40<05:39,  1.19batch/s, Loss=0.1563, Batch=49/452]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 50/452 [00:41<05:38,  1.19batch/s, Loss=0.1563, Batch=49/452]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 50/452 [00:41<05:38,  1.19batch/s, Loss=0.1542, Batch=50/452]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█▏        | 51/452 [00:42<05:38,  1.19batch/s, Loss=0.1542, Batch=50/452]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█▏        | 51/452 [00:42<05:38,  1.19batch/s, Loss=0.1521, Batch=51/452]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 52/452 [00:43<05:36,  1.19batch/s, Loss=0.1521, Batch=51/452]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 52/452 [00:43<05:36,  1.19batch/s, Loss=0.1502, Batch=52/452]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 53/452 [00:44<05:35,  1.19batch/s, Loss=0.1502, Batch=52/452]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 53/452 [00:44<05:35,  1.19batch/s, Loss=0.1483, Batch=53/452]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 54/452 [00:45<05:34,  1.19batch/s, Loss=0.1483, Batch=53/452]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 54/452 [00:45<05:34,  1.19batch/s, Loss=0.1464, Batch=54/452]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 55/452 [00:45<05:34,  1.19batch/s, Loss=0.1464, Batch=54/452]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 55/452 [00:45<05:34,  1.19batch/s, Loss=0.1447, Batch=55/452]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 56/452 [00:46<05:33,  1.19batch/s, Loss=0.1447, Batch=55/452]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 56/452 [00:46<05:33,  1.19batch/s, Loss=0.1430, Batch=56/452]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 57/452 [00:47<05:32,  1.19batch/s, Loss=0.1430, Batch=56/452]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 57/452 [00:47<05:32,  1.19batch/s, Loss=0.1414, Batch=57/452]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 58/452 [00:48<05:31,  1.19batch/s, Loss=0.1414, Batch=57/452]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 58/452 [00:48<05:31,  1.19batch/s, Loss=0.1399, Batch=58/452]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 59/452 [00:49<05:31,  1.19batch/s, Loss=0.1399, Batch=58/452]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 59/452 [00:49<05:31,  1.19batch/s, Loss=0.1384, Batch=59/452]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 60/452 [00:50<05:30,  1.19batch/s, Loss=0.1384, Batch=59/452]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 60/452 [00:50<05:30,  1.19batch/s, Loss=0.1369, Batch=60/452]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 61/452 [00:50<05:28,  1.19batch/s, Loss=0.1369, Batch=60/452]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 61/452 [00:50<05:28,  1.19batch/s, Loss=0.1355, Batch=61/452]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▎        | 62/452 [00:51<05:28,  1.19batch/s, Loss=0.1355, Batch=61/452]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▎        | 62/452 [00:51<05:28,  1.19batch/s, Loss=0.1340, Batch=62/452]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 63/452 [00:52<05:27,  1.19batch/s, Loss=0.1340, Batch=62/452]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 63/452 [00:52<05:27,  1.19batch/s, Loss=0.1326, Batch=63/452]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 64/452 [00:53<05:26,  1.19batch/s, Loss=0.1326, Batch=63/452]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 64/452 [00:53<05:26,  1.19batch/s, Loss=0.1312, Batch=64/452]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 65/452 [00:54<05:25,  1.19batch/s, Loss=0.1312, Batch=64/452]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 65/452 [00:54<05:25,  1.19batch/s, Loss=0.1299, Batch=65/452]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▍        | 66/452 [00:55<05:24,  1.19batch/s, Loss=0.1299, Batch=65/452]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▍        | 66/452 [00:55<05:24,  1.19batch/s, Loss=0.1286, Batch=66/452]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▍        | 67/452 [00:55<05:23,  1.19batch/s, Loss=0.1286, Batch=66/452]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▍        | 67/452 [00:55<05:23,  1.19batch/s, Loss=0.1273, Batch=67/452]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 68/452 [00:56<05:23,  1.19batch/s, Loss=0.1273, Batch=67/452]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 68/452 [00:56<05:23,  1.19batch/s, Loss=0.1261, Batch=68/452]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 69/452 [00:57<05:22,  1.19batch/s, Loss=0.1261, Batch=68/452]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 69/452 [00:57<05:22,  1.19batch/s, Loss=0.1249, Batch=69/452]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 70/452 [00:58<05:21,  1.19batch/s, Loss=0.1249, Batch=69/452]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 70/452 [00:58<05:21,  1.19batch/s, Loss=0.1237, Batch=70/452]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 71/452 [00:59<05:20,  1.19batch/s, Loss=0.1237, Batch=70/452]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 71/452 [00:59<05:20,  1.19batch/s, Loss=0.1225, Batch=71/452]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 72/452 [01:00<05:19,  1.19batch/s, Loss=0.1225, Batch=71/452]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 72/452 [01:00<05:19,  1.19batch/s, Loss=0.1214, Batch=72/452]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 73/452 [01:01<05:19,  1.19batch/s, Loss=0.1214, Batch=72/452]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 73/452 [01:01<05:19,  1.19batch/s, Loss=0.1202, Batch=73/452]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▋        | 74/452 [01:01<05:19,  1.18batch/s, Loss=0.1202, Batch=73/452]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▋        | 74/452 [01:01<05:19,  1.18batch/s, Loss=0.1192, Batch=74/452]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 75/452 [01:02<05:18,  1.19batch/s, Loss=0.1192, Batch=74/452]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 75/452 [01:02<05:18,  1.19batch/s, Loss=0.1181, Batch=75/452]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 76/452 [01:03<05:16,  1.19batch/s, Loss=0.1181, Batch=75/452]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 76/452 [01:03<05:16,  1.19batch/s, Loss=0.1171, Batch=76/452]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 77/452 [01:04<05:16,  1.18batch/s, Loss=0.1171, Batch=76/452]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 77/452 [01:04<05:16,  1.18batch/s, Loss=0.1160, Batch=77/452]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 78/452 [01:05<05:15,  1.19batch/s, Loss=0.1160, Batch=77/452]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 78/452 [01:05<05:15,  1.19batch/s, Loss=0.1149, Batch=78/452]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 79/452 [01:06<05:14,  1.19batch/s, Loss=0.1149, Batch=78/452]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 79/452 [01:06<05:14,  1.19batch/s, Loss=0.1139, Batch=79/452]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 80/452 [01:06<05:13,  1.19batch/s, Loss=0.1139, Batch=79/452]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 80/452 [01:06<05:13,  1.19batch/s, Loss=0.1129, Batch=80/452]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 81/452 [01:07<05:12,  1.19batch/s, Loss=0.1129, Batch=80/452]\u001b[A\u001b[A\n",
            "\n",
            "  8%|▊         | 34/452 [14:55<3:03:27, 26.33s/batch, Loss=0.1871, Batch=34/452]\n",
            "\n",
            "\n",
            " 18%|█▊        | 82/452 [01:08<05:11,  1.19batch/s, Loss=0.1119, Batch=81/452]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 82/452 [01:08<05:11,  1.19batch/s, Loss=0.1108, Batch=82/452]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 83/452 [01:09<05:11,  1.18batch/s, Loss=0.1108, Batch=82/452]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 83/452 [01:09<05:11,  1.18batch/s, Loss=0.1098, Batch=83/452]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▊        | 84/452 [01:10<05:06,  1.20batch/s, Loss=0.1098, Batch=83/452]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▊        | 84/452 [01:10<05:06,  1.20batch/s, Loss=0.1088, Batch=84/452]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 85/452 [01:11<05:01,  1.22batch/s, Loss=0.1088, Batch=84/452]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 85/452 [01:11<05:01,  1.22batch/s, Loss=0.1078, Batch=85/452]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 86/452 [01:11<04:58,  1.23batch/s, Loss=0.1078, Batch=85/452]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 86/452 [01:11<04:58,  1.23batch/s, Loss=0.1068, Batch=86/452]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 87/452 [01:12<04:55,  1.23batch/s, Loss=0.1068, Batch=86/452]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 87/452 [01:12<04:55,  1.23batch/s, Loss=0.1058, Batch=87/452]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 88/452 [01:13<04:53,  1.24batch/s, Loss=0.1058, Batch=87/452]\u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 88/452 [01:13<04:53,  1.24batch/s, Loss=0.1048, Batch=88/452]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 89/452 [01:14<04:51,  1.24batch/s, Loss=0.1048, Batch=88/452]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 89/452 [01:14<04:51,  1.24batch/s, Loss=0.1038, Batch=89/452]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 90/452 [01:15<04:50,  1.25batch/s, Loss=0.1038, Batch=89/452]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 90/452 [01:15<04:50,  1.25batch/s, Loss=0.1028, Batch=90/452]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 91/452 [01:15<04:49,  1.25batch/s, Loss=0.1028, Batch=90/452]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 91/452 [01:15<04:49,  1.25batch/s, Loss=0.1018, Batch=91/452]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 92/452 [01:16<04:48,  1.25batch/s, Loss=0.1018, Batch=91/452]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 92/452 [01:16<04:48,  1.25batch/s, Loss=0.1009, Batch=92/452]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 93/452 [01:17<04:47,  1.25batch/s, Loss=0.1009, Batch=92/452]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 93/452 [01:17<04:47,  1.25batch/s, Loss=0.0999, Batch=93/452]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 94/452 [01:18<04:46,  1.25batch/s, Loss=0.0999, Batch=93/452]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 94/452 [01:18<04:46,  1.25batch/s, Loss=0.0990, Batch=94/452]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 95/452 [01:19<04:45,  1.25batch/s, Loss=0.0990, Batch=94/452]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 95/452 [01:19<04:45,  1.25batch/s, Loss=0.0981, Batch=95/452]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 96/452 [01:19<04:45,  1.25batch/s, Loss=0.0981, Batch=95/452]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 96/452 [01:19<04:45,  1.25batch/s, Loss=0.0973, Batch=96/452]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██▏       | 97/452 [01:20<04:44,  1.25batch/s, Loss=0.0973, Batch=96/452]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██▏       | 97/452 [01:20<04:44,  1.25batch/s, Loss=0.0965, Batch=97/452]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 98/452 [01:21<04:44,  1.24batch/s, Loss=0.0965, Batch=97/452]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 98/452 [01:21<04:44,  1.24batch/s, Loss=0.0957, Batch=98/452]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 99/452 [01:22<04:43,  1.24batch/s, Loss=0.0957, Batch=98/452]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 99/452 [01:22<04:43,  1.24batch/s, Loss=0.0948, Batch=99/452]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 100/452 [01:23<04:42,  1.25batch/s, Loss=0.0948, Batch=99/452]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 100/452 [01:23<04:42,  1.25batch/s, Loss=0.0940, Batch=100/452]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 101/452 [01:23<04:40,  1.25batch/s, Loss=0.0940, Batch=100/452]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 101/452 [01:23<04:40,  1.25batch/s, Loss=0.0932, Batch=101/452]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 102/452 [01:24<04:40,  1.25batch/s, Loss=0.0932, Batch=101/452]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 102/452 [01:24<04:40,  1.25batch/s, Loss=0.0924, Batch=102/452]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 103/452 [01:25<04:39,  1.25batch/s, Loss=0.0924, Batch=102/452]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 103/452 [01:25<04:39,  1.25batch/s, Loss=0.0916, Batch=103/452]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 104/452 [01:26<04:37,  1.25batch/s, Loss=0.0916, Batch=103/452]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 104/452 [01:26<04:37,  1.25batch/s, Loss=0.0908, Batch=104/452]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 105/452 [01:27<04:37,  1.25batch/s, Loss=0.0908, Batch=104/452]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 105/452 [01:27<04:37,  1.25batch/s, Loss=0.0900, Batch=105/452]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 106/452 [01:27<04:36,  1.25batch/s, Loss=0.0900, Batch=105/452]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 106/452 [01:27<04:36,  1.25batch/s, Loss=0.0892, Batch=106/452]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▎       | 107/452 [01:28<04:35,  1.25batch/s, Loss=0.0892, Batch=106/452]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▎       | 107/452 [01:28<04:35,  1.25batch/s, Loss=0.0885, Batch=107/452]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 108/452 [01:29<04:35,  1.25batch/s, Loss=0.0885, Batch=107/452]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 108/452 [01:29<04:35,  1.25batch/s, Loss=0.0877, Batch=108/452]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 109/452 [01:30<04:35,  1.25batch/s, Loss=0.0877, Batch=108/452]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 109/452 [01:30<04:35,  1.25batch/s, Loss=0.0870, Batch=109/452]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 110/452 [01:31<04:33,  1.25batch/s, Loss=0.0870, Batch=109/452]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 110/452 [01:31<04:33,  1.25batch/s, Loss=0.0862, Batch=110/452]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 111/452 [01:31<04:32,  1.25batch/s, Loss=0.0862, Batch=110/452]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 111/452 [01:31<04:32,  1.25batch/s, Loss=0.0855, Batch=111/452]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 112/452 [01:32<04:32,  1.25batch/s, Loss=0.0855, Batch=111/452]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 112/452 [01:32<04:32,  1.25batch/s, Loss=0.0848, Batch=112/452]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 113/452 [01:33<04:31,  1.25batch/s, Loss=0.0848, Batch=112/452]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 113/452 [01:33<04:31,  1.25batch/s, Loss=0.0841, Batch=113/452]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 114/452 [01:34<04:29,  1.25batch/s, Loss=0.0841, Batch=113/452]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 114/452 [01:34<04:29,  1.25batch/s, Loss=0.0834, Batch=114/452]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 115/452 [01:35<04:29,  1.25batch/s, Loss=0.0834, Batch=114/452]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 115/452 [01:35<04:29,  1.25batch/s, Loss=0.0827, Batch=115/452]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 116/452 [01:35<04:28,  1.25batch/s, Loss=0.0827, Batch=115/452]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 116/452 [01:35<04:28,  1.25batch/s, Loss=0.0821, Batch=116/452]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 117/452 [01:36<04:28,  1.25batch/s, Loss=0.0821, Batch=116/452]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 117/452 [01:36<04:28,  1.25batch/s, Loss=0.0814, Batch=117/452]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 118/452 [01:37<04:27,  1.25batch/s, Loss=0.0814, Batch=117/452]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 118/452 [01:37<04:27,  1.25batch/s, Loss=0.0808, Batch=118/452]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▋       | 119/452 [01:38<04:26,  1.25batch/s, Loss=0.0808, Batch=118/452]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▋       | 119/452 [01:38<04:26,  1.25batch/s, Loss=0.0801, Batch=119/452]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 120/452 [01:39<04:25,  1.25batch/s, Loss=0.0801, Batch=119/452]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 120/452 [01:39<04:25,  1.25batch/s, Loss=0.0795, Batch=120/452]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 121/452 [01:39<04:24,  1.25batch/s, Loss=0.0795, Batch=120/452]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 121/452 [01:39<04:24,  1.25batch/s, Loss=0.0789, Batch=121/452]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 122/452 [01:40<04:24,  1.25batch/s, Loss=0.0789, Batch=121/452]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 122/452 [01:40<04:24,  1.25batch/s, Loss=0.0783, Batch=122/452]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 123/452 [01:41<04:23,  1.25batch/s, Loss=0.0783, Batch=122/452]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 123/452 [01:41<04:23,  1.25batch/s, Loss=0.0777, Batch=123/452]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 124/452 [01:42<04:22,  1.25batch/s, Loss=0.0777, Batch=123/452]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 124/452 [01:42<04:22,  1.25batch/s, Loss=0.0771, Batch=124/452]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 125/452 [01:43<04:20,  1.25batch/s, Loss=0.0771, Batch=124/452]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 125/452 [01:43<04:20,  1.25batch/s, Loss=0.0765, Batch=125/452]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 126/452 [01:44<05:40,  1.05s/batch, Loss=0.0765, Batch=125/452]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 126/452 [01:44<05:40,  1.05s/batch, Loss=0.0759, Batch=126/452]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 127/452 [01:45<05:19,  1.02batch/s, Loss=0.0759, Batch=126/452]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 127/452 [01:45<05:19,  1.02batch/s, Loss=0.0754, Batch=127/452]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 128/452 [01:46<05:00,  1.08batch/s, Loss=0.0754, Batch=127/452]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 128/452 [01:46<05:00,  1.08batch/s, Loss=0.0748, Batch=128/452]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▊       | 129/452 [01:47<05:32,  1.03s/batch, Loss=0.0748, Batch=128/452]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▊       | 129/452 [01:47<05:32,  1.03s/batch, Loss=0.0743, Batch=129/452]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 130/452 [01:48<05:09,  1.04batch/s, Loss=0.0743, Batch=129/452]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 130/452 [01:48<05:09,  1.04batch/s, Loss=0.0737, Batch=130/452]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 131/452 [01:49<04:53,  1.09batch/s, Loss=0.0737, Batch=130/452]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 131/452 [01:49<04:53,  1.09batch/s, Loss=0.0732, Batch=131/452]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 132/452 [01:50<05:35,  1.05s/batch, Loss=0.0732, Batch=131/452]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 132/452 [01:50<05:35,  1.05s/batch, Loss=0.0727, Batch=132/452]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 133/452 [01:51<05:10,  1.03batch/s, Loss=0.0727, Batch=132/452]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 133/452 [01:51<05:10,  1.03batch/s, Loss=0.0721, Batch=133/452]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 134/452 [01:52<04:52,  1.09batch/s, Loss=0.0721, Batch=133/452]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 134/452 [01:52<04:52,  1.09batch/s, Loss=0.0716, Batch=134/452]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 135/452 [01:53<05:39,  1.07s/batch, Loss=0.0716, Batch=134/452]\u001b[A\u001b[A\n",
            "\n",
            " 30%|██▉       | 135/452 [01:53<05:39,  1.07s/batch, Loss=0.0711, Batch=135/452]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 136/452 [01:54<05:25,  1.03s/batch, Loss=0.0711, Batch=135/452]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 136/452 [01:54<05:25,  1.03s/batch, Loss=0.0706, Batch=136/452]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 137/452 [01:55<05:02,  1.04batch/s, Loss=0.0706, Batch=136/452]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 137/452 [01:55<05:02,  1.04batch/s, Loss=0.0701, Batch=137/452]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 138/452 [01:56<04:46,  1.10batch/s, Loss=0.0701, Batch=137/452]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 138/452 [01:56<04:46,  1.10batch/s, Loss=0.0696, Batch=138/452]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 139/452 [01:57<04:36,  1.13batch/s, Loss=0.0696, Batch=138/452]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 139/452 [01:57<04:36,  1.13batch/s, Loss=0.0691, Batch=139/452]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 140/452 [01:57<04:40,  1.11batch/s, Loss=0.0691, Batch=139/452]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 140/452 [01:57<04:40,  1.11batch/s, Loss=0.0687, Batch=140/452]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 141/452 [01:58<04:29,  1.15batch/s, Loss=0.0687, Batch=140/452]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 141/452 [01:58<04:29,  1.15batch/s, Loss=0.0682, Batch=141/452]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███▏      | 142/452 [01:59<04:36,  1.12batch/s, Loss=0.0682, Batch=141/452]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███▏      | 142/452 [01:59<04:36,  1.12batch/s, Loss=0.0677, Batch=142/452]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 143/452 [02:00<04:37,  1.11batch/s, Loss=0.0677, Batch=142/452]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 143/452 [02:00<04:37,  1.11batch/s, Loss=0.0673, Batch=143/452]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 144/452 [02:01<04:27,  1.15batch/s, Loss=0.0673, Batch=143/452]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 144/452 [02:01<04:27,  1.15batch/s, Loss=0.0668, Batch=144/452]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 145/452 [02:02<05:03,  1.01batch/s, Loss=0.0668, Batch=144/452]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 145/452 [02:02<05:03,  1.01batch/s, Loss=0.0664, Batch=145/452]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 146/452 [02:03<04:44,  1.07batch/s, Loss=0.0664, Batch=145/452]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 146/452 [02:03<04:44,  1.07batch/s, Loss=0.0659, Batch=146/452]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 147/452 [02:04<04:31,  1.12batch/s, Loss=0.0659, Batch=146/452]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 147/452 [02:04<04:31,  1.12batch/s, Loss=0.0655, Batch=147/452]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 148/452 [02:05<05:26,  1.07s/batch, Loss=0.0655, Batch=147/452]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 148/452 [02:05<05:26,  1.07s/batch, Loss=0.0651, Batch=148/452]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 149/452 [02:06<05:12,  1.03s/batch, Loss=0.0651, Batch=148/452]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 149/452 [02:06<05:12,  1.03s/batch, Loss=0.0646, Batch=149/452]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 150/452 [02:07<05:07,  1.02s/batch, Loss=0.0646, Batch=149/452]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 150/452 [02:07<05:07,  1.02s/batch, Loss=0.0642, Batch=150/452]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 151/452 [02:08<05:05,  1.02s/batch, Loss=0.0642, Batch=150/452]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 151/452 [02:08<05:05,  1.02s/batch, Loss=0.0638, Batch=151/452]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▎      | 152/452 [02:09<05:02,  1.01s/batch, Loss=0.0638, Batch=151/452]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▎      | 152/452 [02:09<05:02,  1.01s/batch, Loss=0.0634, Batch=152/452]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 153/452 [02:10<05:01,  1.01s/batch, Loss=0.0634, Batch=152/452]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 153/452 [02:10<05:01,  1.01s/batch, Loss=0.0630, Batch=153/452]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 154/452 [02:11<04:41,  1.06batch/s, Loss=0.0630, Batch=153/452]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 154/452 [02:11<04:41,  1.06batch/s, Loss=0.0626, Batch=154/452]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 155/452 [02:12<04:56,  1.00batch/s, Loss=0.0626, Batch=154/452]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 155/452 [02:12<04:56,  1.00batch/s, Loss=0.0622, Batch=155/452]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 156/452 [02:13<04:37,  1.07batch/s, Loss=0.0622, Batch=155/452]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 156/452 [02:13<04:37,  1.07batch/s, Loss=0.0618, Batch=156/452]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 157/452 [02:14<05:10,  1.05s/batch, Loss=0.0618, Batch=156/452]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 157/452 [02:14<05:10,  1.05s/batch, Loss=0.0614, Batch=157/452]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 158/452 [02:15<05:02,  1.03s/batch, Loss=0.0614, Batch=157/452]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▍      | 158/452 [02:15<05:02,  1.03s/batch, Loss=0.0610, Batch=158/452]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 159/452 [02:16<04:57,  1.02s/batch, Loss=0.0610, Batch=158/452]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 159/452 [02:16<04:57,  1.02s/batch, Loss=0.0606, Batch=159/452]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 160/452 [02:17<04:55,  1.01s/batch, Loss=0.0606, Batch=159/452]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 160/452 [02:17<04:55,  1.01s/batch, Loss=0.0602, Batch=160/452]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 161/452 [02:18<04:53,  1.01s/batch, Loss=0.0602, Batch=160/452]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 161/452 [02:18<04:53,  1.01s/batch, Loss=0.0599, Batch=161/452]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 162/452 [02:19<04:52,  1.01s/batch, Loss=0.0599, Batch=161/452]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 162/452 [02:19<04:52,  1.01s/batch, Loss=0.0595, Batch=162/452]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 163/452 [02:20<04:33,  1.06batch/s, Loss=0.0595, Batch=162/452]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▌      | 163/452 [02:20<04:33,  1.06batch/s, Loss=0.0592, Batch=163/452]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▋      | 164/452 [02:21<04:47,  1.00batch/s, Loss=0.0592, Batch=163/452]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▋      | 164/452 [02:21<04:47,  1.00batch/s, Loss=0.0588, Batch=164/452]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 165/452 [02:22<04:56,  1.03s/batch, Loss=0.0588, Batch=164/452]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 165/452 [02:22<04:56,  1.03s/batch, Loss=0.0584, Batch=165/452]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 166/452 [02:23<04:49,  1.01s/batch, Loss=0.0584, Batch=165/452]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 166/452 [02:23<04:49,  1.01s/batch, Loss=0.0581, Batch=166/452]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 167/452 [02:24<04:47,  1.01s/batch, Loss=0.0581, Batch=166/452]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 167/452 [02:24<04:47,  1.01s/batch, Loss=0.0577, Batch=167/452]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 168/452 [02:25<04:45,  1.00s/batch, Loss=0.0577, Batch=167/452]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 168/452 [02:25<04:45,  1.00s/batch, Loss=0.0574, Batch=168/452]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 169/452 [02:26<04:43,  1.00s/batch, Loss=0.0574, Batch=168/452]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 169/452 [02:26<04:43,  1.00s/batch, Loss=0.0571, Batch=169/452]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 170/452 [02:27<04:25,  1.06batch/s, Loss=0.0571, Batch=169/452]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 170/452 [02:27<04:25,  1.06batch/s, Loss=0.0567, Batch=170/452]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 171/452 [02:28<04:38,  1.01batch/s, Loss=0.0567, Batch=170/452]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 171/452 [02:28<04:38,  1.01batch/s, Loss=0.0564, Batch=171/452]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 172/452 [02:29<04:21,  1.07batch/s, Loss=0.0564, Batch=171/452]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 172/452 [02:29<04:21,  1.07batch/s, Loss=0.0561, Batch=172/452]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 173/452 [02:30<04:48,  1.03s/batch, Loss=0.0561, Batch=172/452]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 173/452 [02:30<04:48,  1.03s/batch, Loss=0.0557, Batch=173/452]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 174/452 [02:31<04:28,  1.04batch/s, Loss=0.0557, Batch=173/452]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 174/452 [02:31<04:28,  1.04batch/s, Loss=0.0554, Batch=174/452]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▊      | 175/452 [02:32<04:13,  1.09batch/s, Loss=0.0554, Batch=174/452]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▊      | 175/452 [02:32<04:13,  1.09batch/s, Loss=0.0551, Batch=175/452]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 176/452 [02:33<04:54,  1.07s/batch, Loss=0.0551, Batch=175/452]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 176/452 [02:33<04:54,  1.07s/batch, Loss=0.0548, Batch=176/452]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 177/452 [02:34<04:41,  1.02s/batch, Loss=0.0548, Batch=176/452]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 177/452 [02:34<04:41,  1.02s/batch, Loss=0.0545, Batch=177/452]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 178/452 [02:35<04:48,  1.05s/batch, Loss=0.0545, Batch=177/452]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 178/452 [02:35<04:48,  1.05s/batch, Loss=0.0542, Batch=178/452]\u001b[A\u001b[A\n",
            "\n",
            " 40%|███▉      | 179/452 [02:36<04:40,  1.03s/batch, Loss=0.0542, Batch=178/452]\u001b[A\u001b[A\n",
            "\n",
            " 40%|███▉      | 179/452 [02:36<04:40,  1.03s/batch, Loss=0.0539, Batch=179/452]\u001b[A\u001b[A\n",
            "\n",
            " 40%|███▉      | 180/452 [02:37<04:36,  1.02s/batch, Loss=0.0539, Batch=179/452]\u001b[A\u001b[A\n",
            "\n",
            " 40%|███▉      | 180/452 [02:37<04:36,  1.02s/batch, Loss=0.0536, Batch=180/452]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 181/452 [02:38<04:33,  1.01s/batch, Loss=0.0536, Batch=180/452]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 181/452 [02:38<04:33,  1.01s/batch, Loss=0.0533, Batch=181/452]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 182/452 [02:39<04:14,  1.06batch/s, Loss=0.0533, Batch=181/452]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 182/452 [02:39<04:14,  1.06batch/s, Loss=0.0530, Batch=182/452]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 183/452 [02:40<04:29,  1.00s/batch, Loss=0.0530, Batch=182/452]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 183/452 [02:40<04:29,  1.00s/batch, Loss=0.0527, Batch=183/452]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 184/452 [02:41<04:11,  1.06batch/s, Loss=0.0527, Batch=183/452]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 184/452 [02:41<04:11,  1.06batch/s, Loss=0.0524, Batch=184/452]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 185/452 [02:42<04:37,  1.04s/batch, Loss=0.0524, Batch=184/452]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 185/452 [02:42<04:37,  1.04s/batch, Loss=0.0521, Batch=185/452]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 186/452 [02:43<04:17,  1.03batch/s, Loss=0.0521, Batch=185/452]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████      | 186/452 [02:43<04:17,  1.03batch/s, Loss=0.0519, Batch=186/452]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████▏     | 187/452 [02:44<04:02,  1.09batch/s, Loss=0.0519, Batch=186/452]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████▏     | 187/452 [02:44<04:02,  1.09batch/s, Loss=0.0516, Batch=187/452]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 188/452 [02:45<04:39,  1.06s/batch, Loss=0.0516, Batch=187/452]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 188/452 [02:45<04:39,  1.06s/batch, Loss=0.0513, Batch=188/452]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 189/452 [02:46<04:17,  1.02batch/s, Loss=0.0513, Batch=188/452]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 189/452 [02:46<04:17,  1.02batch/s, Loss=0.0510, Batch=189/452]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 190/452 [02:47<04:02,  1.08batch/s, Loss=0.0510, Batch=189/452]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 190/452 [02:47<04:02,  1.08batch/s, Loss=0.0508, Batch=190/452]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 191/452 [02:48<04:41,  1.08s/batch, Loss=0.0508, Batch=190/452]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 191/452 [02:48<04:41,  1.08s/batch, Loss=0.0505, Batch=191/452]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 192/452 [02:49<04:26,  1.02s/batch, Loss=0.0505, Batch=191/452]\u001b[A\u001b[A\n",
            "\n",
            " 42%|████▏     | 192/452 [02:49<04:26,  1.02s/batch, Loss=0.0502, Batch=192/452]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 193/452 [02:50<04:07,  1.05batch/s, Loss=0.0502, Batch=192/452]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 193/452 [02:50<04:07,  1.05batch/s, Loss=0.0500, Batch=193/452]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 194/452 [02:51<04:36,  1.07s/batch, Loss=0.0500, Batch=193/452]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 194/452 [02:51<04:36,  1.07s/batch, Loss=0.0497, Batch=194/452]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 195/452 [02:52<04:27,  1.04s/batch, Loss=0.0497, Batch=194/452]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 195/452 [02:52<04:27,  1.04s/batch, Loss=0.0495, Batch=195/452]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 196/452 [02:53<04:07,  1.03batch/s, Loss=0.0495, Batch=195/452]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 196/452 [02:53<04:07,  1.03batch/s, Loss=0.0492, Batch=196/452]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▎     | 197/452 [02:54<04:27,  1.05s/batch, Loss=0.0492, Batch=196/452]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▎     | 197/452 [02:54<04:27,  1.05s/batch, Loss=0.0490, Batch=197/452]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 198/452 [02:55<04:07,  1.03batch/s, Loss=0.0490, Batch=197/452]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 198/452 [02:55<04:07,  1.03batch/s, Loss=0.0487, Batch=198/452]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 199/452 [02:56<03:53,  1.08batch/s, Loss=0.0487, Batch=198/452]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 199/452 [02:56<03:53,  1.08batch/s, Loss=0.0485, Batch=199/452]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 200/452 [02:57<04:28,  1.07s/batch, Loss=0.0485, Batch=199/452]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 200/452 [02:57<04:28,  1.07s/batch, Loss=0.0482, Batch=200/452]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 201/452 [02:58<04:19,  1.03s/batch, Loss=0.0482, Batch=200/452]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▍     | 201/452 [02:58<04:19,  1.03s/batch, Loss=0.0480, Batch=201/452]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 202/452 [02:59<04:16,  1.02s/batch, Loss=0.0480, Batch=201/452]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 202/452 [02:59<04:16,  1.02s/batch, Loss=0.0478, Batch=202/452]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 203/452 [03:00<04:12,  1.02s/batch, Loss=0.0478, Batch=202/452]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 203/452 [03:00<04:12,  1.02s/batch, Loss=0.0475, Batch=203/452]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 204/452 [03:01<04:11,  1.01s/batch, Loss=0.0475, Batch=203/452]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 204/452 [03:01<04:11,  1.01s/batch, Loss=0.0473, Batch=204/452]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 205/452 [03:02<04:08,  1.01s/batch, Loss=0.0473, Batch=204/452]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▌     | 205/452 [03:02<04:08,  1.01s/batch, Loss=0.0471, Batch=205/452]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 206/452 [03:03<03:52,  1.06batch/s, Loss=0.0471, Batch=205/452]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 206/452 [03:03<03:52,  1.06batch/s, Loss=0.0468, Batch=206/452]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 207/452 [03:04<04:03,  1.00batch/s, Loss=0.0468, Batch=206/452]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 207/452 [03:04<04:03,  1.00batch/s, Loss=0.0466, Batch=207/452]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 208/452 [03:05<03:48,  1.07batch/s, Loss=0.0466, Batch=207/452]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 208/452 [03:05<03:48,  1.07batch/s, Loss=0.0464, Batch=208/452]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 209/452 [03:06<04:13,  1.04s/batch, Loss=0.0464, Batch=208/452]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 209/452 [03:06<04:13,  1.04s/batch, Loss=0.0462, Batch=209/452]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▋     | 210/452 [03:07<04:08,  1.03s/batch, Loss=0.0462, Batch=209/452]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▋     | 210/452 [03:07<04:08,  1.03s/batch, Loss=0.0460, Batch=210/452]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 211/452 [03:08<04:06,  1.02s/batch, Loss=0.0460, Batch=210/452]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 211/452 [03:08<04:06,  1.02s/batch, Loss=0.0457, Batch=211/452]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 212/452 [03:09<04:03,  1.02s/batch, Loss=0.0457, Batch=211/452]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 212/452 [03:09<04:03,  1.02s/batch, Loss=0.0455, Batch=212/452]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 213/452 [03:10<04:01,  1.01s/batch, Loss=0.0455, Batch=212/452]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 213/452 [03:10<04:01,  1.01s/batch, Loss=0.0453, Batch=213/452]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 214/452 [03:11<03:59,  1.01s/batch, Loss=0.0453, Batch=213/452]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 214/452 [03:11<03:59,  1.01s/batch, Loss=0.0451, Batch=214/452]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 215/452 [03:12<03:58,  1.01s/batch, Loss=0.0451, Batch=214/452]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 215/452 [03:12<03:58,  1.01s/batch, Loss=0.0449, Batch=215/452]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 216/452 [03:13<03:56,  1.00s/batch, Loss=0.0449, Batch=215/452]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 216/452 [03:13<03:56,  1.00s/batch, Loss=0.0447, Batch=216/452]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 217/452 [03:14<03:55,  1.00s/batch, Loss=0.0447, Batch=216/452]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 217/452 [03:14<03:55,  1.00s/batch, Loss=0.0445, Batch=217/452]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 218/452 [03:15<03:54,  1.00s/batch, Loss=0.0445, Batch=217/452]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 218/452 [03:15<03:54,  1.00s/batch, Loss=0.0443, Batch=218/452]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 219/452 [03:16<03:53,  1.00s/batch, Loss=0.0443, Batch=218/452]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 219/452 [03:16<03:53,  1.00s/batch, Loss=0.0441, Batch=219/452]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▊     | 220/452 [03:17<03:38,  1.06batch/s, Loss=0.0441, Batch=219/452]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▊     | 220/452 [03:17<03:38,  1.06batch/s, Loss=0.0439, Batch=220/452]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 221/452 [03:18<03:57,  1.03s/batch, Loss=0.0439, Batch=220/452]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 221/452 [03:18<03:57,  1.03s/batch, Loss=0.0437, Batch=221/452]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 222/452 [03:19<03:40,  1.04batch/s, Loss=0.0437, Batch=221/452]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 222/452 [03:19<03:40,  1.04batch/s, Loss=0.0435, Batch=222/452]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 223/452 [03:20<03:57,  1.04s/batch, Loss=0.0435, Batch=222/452]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▉     | 223/452 [03:20<03:57,  1.04s/batch, Loss=0.0433, Batch=223/452]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 224/452 [03:21<03:50,  1.01s/batch, Loss=0.0433, Batch=223/452]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 224/452 [03:21<03:50,  1.01s/batch, Loss=0.0431, Batch=224/452]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 225/452 [03:22<03:35,  1.06batch/s, Loss=0.0431, Batch=224/452]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 225/452 [03:22<03:35,  1.06batch/s, Loss=0.0429, Batch=225/452]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 226/452 [03:23<03:23,  1.11batch/s, Loss=0.0429, Batch=225/452]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 226/452 [03:23<03:23,  1.11batch/s, Loss=0.0427, Batch=226/452]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 227/452 [03:23<03:15,  1.15batch/s, Loss=0.0427, Batch=226/452]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 227/452 [03:23<03:15,  1.15batch/s, Loss=0.0425, Batch=227/452]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 228/452 [03:24<03:10,  1.18batch/s, Loss=0.0425, Batch=227/452]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 228/452 [03:24<03:10,  1.18batch/s, Loss=0.0423, Batch=228/452]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 229/452 [03:25<03:05,  1.20batch/s, Loss=0.0423, Batch=228/452]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 229/452 [03:25<03:05,  1.20batch/s, Loss=0.0422, Batch=229/452]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 230/452 [03:26<03:02,  1.22batch/s, Loss=0.0422, Batch=229/452]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 230/452 [03:26<03:02,  1.22batch/s, Loss=0.0420, Batch=230/452]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 231/452 [03:27<03:00,  1.23batch/s, Loss=0.0420, Batch=230/452]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 231/452 [03:27<03:00,  1.23batch/s, Loss=0.0418, Batch=231/452]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████▏    | 232/452 [03:27<02:58,  1.23batch/s, Loss=0.0418, Batch=231/452]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████▏    | 232/452 [03:27<02:58,  1.23batch/s, Loss=0.0416, Batch=232/452]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 233/452 [03:28<02:56,  1.24batch/s, Loss=0.0416, Batch=232/452]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 233/452 [03:28<02:56,  1.24batch/s, Loss=0.0414, Batch=233/452]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 234/452 [03:29<02:55,  1.25batch/s, Loss=0.0414, Batch=233/452]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 234/452 [03:29<02:55,  1.25batch/s, Loss=0.0413, Batch=234/452]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 235/452 [03:30<02:53,  1.25batch/s, Loss=0.0413, Batch=234/452]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 235/452 [03:30<02:53,  1.25batch/s, Loss=0.0411, Batch=235/452]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 236/452 [03:31<02:52,  1.25batch/s, Loss=0.0411, Batch=235/452]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 236/452 [03:31<02:52,  1.25batch/s, Loss=0.0409, Batch=236/452]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 237/452 [03:31<02:51,  1.25batch/s, Loss=0.0409, Batch=236/452]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 237/452 [03:31<02:51,  1.25batch/s, Loss=0.0407, Batch=237/452]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 238/452 [03:32<02:50,  1.26batch/s, Loss=0.0407, Batch=237/452]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 238/452 [03:32<02:50,  1.26batch/s, Loss=0.0406, Batch=238/452]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 239/452 [03:33<02:49,  1.26batch/s, Loss=0.0406, Batch=238/452]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 239/452 [03:33<02:49,  1.26batch/s, Loss=0.0404, Batch=239/452]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 240/452 [03:34<02:48,  1.26batch/s, Loss=0.0404, Batch=239/452]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 240/452 [03:34<02:48,  1.26batch/s, Loss=0.0402, Batch=240/452]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 241/452 [03:35<02:48,  1.25batch/s, Loss=0.0402, Batch=240/452]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 241/452 [03:35<02:48,  1.25batch/s, Loss=0.0401, Batch=241/452]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▎    | 242/452 [03:35<02:47,  1.26batch/s, Loss=0.0401, Batch=241/452]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▎    | 242/452 [03:35<02:47,  1.26batch/s, Loss=0.0399, Batch=242/452]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 243/452 [03:36<02:46,  1.26batch/s, Loss=0.0399, Batch=242/452]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 243/452 [03:36<02:46,  1.26batch/s, Loss=0.0397, Batch=243/452]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 244/452 [03:37<02:45,  1.26batch/s, Loss=0.0397, Batch=243/452]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 244/452 [03:37<02:45,  1.26batch/s, Loss=0.0396, Batch=244/452]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 245/452 [03:38<02:44,  1.26batch/s, Loss=0.0396, Batch=244/452]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 245/452 [03:38<02:44,  1.26batch/s, Loss=0.0394, Batch=245/452]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 246/452 [03:39<02:43,  1.26batch/s, Loss=0.0394, Batch=245/452]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 246/452 [03:39<02:43,  1.26batch/s, Loss=0.0392, Batch=246/452]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 247/452 [03:39<02:43,  1.26batch/s, Loss=0.0392, Batch=246/452]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 247/452 [03:39<02:43,  1.26batch/s, Loss=0.0391, Batch=247/452]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 248/452 [03:40<02:42,  1.26batch/s, Loss=0.0391, Batch=247/452]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 248/452 [03:40<02:42,  1.26batch/s, Loss=0.0389, Batch=248/452]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 249/452 [03:41<02:41,  1.26batch/s, Loss=0.0389, Batch=248/452]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 249/452 [03:41<02:41,  1.26batch/s, Loss=0.0388, Batch=249/452]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 250/452 [03:42<02:40,  1.26batch/s, Loss=0.0388, Batch=249/452]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▌    | 250/452 [03:42<02:40,  1.26batch/s, Loss=0.0386, Batch=250/452]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 251/452 [03:43<02:39,  1.26batch/s, Loss=0.0386, Batch=250/452]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 251/452 [03:43<02:39,  1.26batch/s, Loss=0.0385, Batch=251/452]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 252/452 [03:43<02:38,  1.26batch/s, Loss=0.0385, Batch=251/452]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 252/452 [03:43<02:38,  1.26batch/s, Loss=0.0383, Batch=252/452]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 253/452 [03:44<02:38,  1.26batch/s, Loss=0.0383, Batch=252/452]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 253/452 [03:44<02:38,  1.26batch/s, Loss=0.0382, Batch=253/452]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 254/452 [03:45<02:37,  1.26batch/s, Loss=0.0382, Batch=253/452]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 254/452 [03:45<02:37,  1.26batch/s, Loss=0.0380, Batch=254/452]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▋    | 255/452 [03:46<02:36,  1.26batch/s, Loss=0.0380, Batch=254/452]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▋    | 255/452 [03:46<02:36,  1.26batch/s, Loss=0.0379, Batch=255/452]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 256/452 [03:47<02:36,  1.25batch/s, Loss=0.0379, Batch=255/452]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 256/452 [03:47<02:36,  1.25batch/s, Loss=0.0377, Batch=256/452]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 257/452 [03:47<02:35,  1.25batch/s, Loss=0.0377, Batch=256/452]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 257/452 [03:47<02:35,  1.25batch/s, Loss=0.0376, Batch=257/452]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 258/452 [03:48<02:34,  1.25batch/s, Loss=0.0376, Batch=257/452]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 258/452 [03:48<02:34,  1.25batch/s, Loss=0.0374, Batch=258/452]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 259/452 [03:49<02:33,  1.25batch/s, Loss=0.0374, Batch=258/452]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 259/452 [03:49<02:33,  1.25batch/s, Loss=0.0373, Batch=259/452]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 260/452 [03:50<02:33,  1.25batch/s, Loss=0.0373, Batch=259/452]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 260/452 [03:50<02:33,  1.25batch/s, Loss=0.0371, Batch=260/452]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 261/452 [03:51<02:32,  1.25batch/s, Loss=0.0371, Batch=260/452]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 261/452 [03:51<02:32,  1.25batch/s, Loss=0.0370, Batch=261/452]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 262/452 [03:51<02:31,  1.25batch/s, Loss=0.0370, Batch=261/452]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 262/452 [03:51<02:31,  1.25batch/s, Loss=0.0369, Batch=262/452]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 263/452 [03:52<02:30,  1.25batch/s, Loss=0.0369, Batch=262/452]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 263/452 [03:52<02:30,  1.25batch/s, Loss=0.0367, Batch=263/452]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 264/452 [03:53<02:29,  1.25batch/s, Loss=0.0367, Batch=263/452]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 264/452 [03:53<02:29,  1.25batch/s, Loss=0.0366, Batch=264/452]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▊    | 265/452 [03:54<02:29,  1.25batch/s, Loss=0.0366, Batch=264/452]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▊    | 265/452 [03:54<02:29,  1.25batch/s, Loss=0.0364, Batch=265/452]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 266/452 [03:55<02:27,  1.26batch/s, Loss=0.0364, Batch=265/452]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 266/452 [03:55<02:27,  1.26batch/s, Loss=0.0363, Batch=266/452]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 267/452 [03:55<02:27,  1.25batch/s, Loss=0.0363, Batch=266/452]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 267/452 [03:55<02:27,  1.25batch/s, Loss=0.0362, Batch=267/452]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 268/452 [03:56<02:26,  1.26batch/s, Loss=0.0362, Batch=267/452]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 268/452 [03:56<02:26,  1.26batch/s, Loss=0.0360, Batch=268/452]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 269/452 [03:57<02:25,  1.25batch/s, Loss=0.0360, Batch=268/452]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 269/452 [03:57<02:25,  1.25batch/s, Loss=0.0359, Batch=269/452]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 270/452 [03:58<02:25,  1.25batch/s, Loss=0.0359, Batch=269/452]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 270/452 [03:58<02:25,  1.25batch/s, Loss=0.0358, Batch=270/452]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 271/452 [03:59<02:24,  1.25batch/s, Loss=0.0358, Batch=270/452]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 271/452 [03:59<02:24,  1.25batch/s, Loss=0.0356, Batch=271/452]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 272/452 [03:59<02:23,  1.25batch/s, Loss=0.0356, Batch=271/452]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 272/452 [03:59<02:23,  1.25batch/s, Loss=0.0355, Batch=272/452]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 273/452 [04:00<02:22,  1.26batch/s, Loss=0.0355, Batch=272/452]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 273/452 [04:00<02:22,  1.26batch/s, Loss=0.0354, Batch=273/452]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 274/452 [04:01<02:21,  1.26batch/s, Loss=0.0354, Batch=273/452]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 274/452 [04:01<02:21,  1.26batch/s, Loss=0.0352, Batch=274/452]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 275/452 [04:02<02:20,  1.26batch/s, Loss=0.0352, Batch=274/452]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 275/452 [04:02<02:20,  1.26batch/s, Loss=0.0351, Batch=275/452]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 276/452 [04:03<02:20,  1.25batch/s, Loss=0.0351, Batch=275/452]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 276/452 [04:03<02:20,  1.25batch/s, Loss=0.0350, Batch=276/452]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████▏   | 277/452 [04:03<02:19,  1.26batch/s, Loss=0.0350, Batch=276/452]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████▏   | 277/452 [04:03<02:19,  1.26batch/s, Loss=0.0349, Batch=277/452]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 278/452 [04:04<02:18,  1.26batch/s, Loss=0.0349, Batch=277/452]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 278/452 [04:04<02:18,  1.26batch/s, Loss=0.0347, Batch=278/452]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 279/452 [04:05<02:17,  1.26batch/s, Loss=0.0347, Batch=278/452]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 279/452 [04:05<02:17,  1.26batch/s, Loss=0.0346, Batch=279/452]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 280/452 [04:06<02:16,  1.26batch/s, Loss=0.0346, Batch=279/452]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 280/452 [04:06<02:16,  1.26batch/s, Loss=0.0345, Batch=280/452]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 281/452 [04:06<02:16,  1.26batch/s, Loss=0.0345, Batch=280/452]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 281/452 [04:06<02:16,  1.26batch/s, Loss=0.0344, Batch=281/452]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 282/452 [04:07<02:15,  1.26batch/s, Loss=0.0344, Batch=281/452]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 282/452 [04:07<02:15,  1.26batch/s, Loss=0.0342, Batch=282/452]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 283/452 [04:08<02:15,  1.25batch/s, Loss=0.0342, Batch=282/452]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 283/452 [04:08<02:15,  1.25batch/s, Loss=0.0341, Batch=283/452]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 284/452 [04:09<02:14,  1.25batch/s, Loss=0.0341, Batch=283/452]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 284/452 [04:09<02:14,  1.25batch/s, Loss=0.0340, Batch=284/452]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 285/452 [04:10<02:13,  1.25batch/s, Loss=0.0340, Batch=284/452]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 285/452 [04:10<02:13,  1.25batch/s, Loss=0.0339, Batch=285/452]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 286/452 [04:10<02:12,  1.25batch/s, Loss=0.0339, Batch=285/452]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 286/452 [04:10<02:12,  1.25batch/s, Loss=0.0338, Batch=286/452]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 287/452 [04:11<02:11,  1.26batch/s, Loss=0.0338, Batch=286/452]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 287/452 [04:11<02:11,  1.26batch/s, Loss=0.0336, Batch=287/452]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▎   | 288/452 [04:12<02:10,  1.26batch/s, Loss=0.0336, Batch=287/452]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▎   | 288/452 [04:12<02:10,  1.26batch/s, Loss=0.0335, Batch=288/452]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 289/452 [04:13<02:09,  1.26batch/s, Loss=0.0335, Batch=288/452]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 289/452 [04:13<02:09,  1.26batch/s, Loss=0.0334, Batch=289/452]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 290/452 [04:14<02:08,  1.26batch/s, Loss=0.0334, Batch=289/452]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 290/452 [04:14<02:08,  1.26batch/s, Loss=0.0333, Batch=290/452]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 291/452 [04:14<02:08,  1.25batch/s, Loss=0.0333, Batch=290/452]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 291/452 [04:14<02:08,  1.25batch/s, Loss=0.0332, Batch=291/452]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 292/452 [04:15<02:07,  1.25batch/s, Loss=0.0332, Batch=291/452]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 292/452 [04:15<02:07,  1.25batch/s, Loss=0.0331, Batch=292/452]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 293/452 [04:16<02:06,  1.26batch/s, Loss=0.0331, Batch=292/452]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▍   | 293/452 [04:16<02:06,  1.26batch/s, Loss=0.0330, Batch=293/452]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 294/452 [04:17<02:05,  1.26batch/s, Loss=0.0330, Batch=293/452]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 294/452 [04:17<02:05,  1.26batch/s, Loss=0.0328, Batch=294/452]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 295/452 [04:18<02:04,  1.26batch/s, Loss=0.0328, Batch=294/452]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 295/452 [04:18<02:04,  1.26batch/s, Loss=0.0327, Batch=295/452]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 296/452 [04:18<02:04,  1.26batch/s, Loss=0.0327, Batch=295/452]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 296/452 [04:18<02:04,  1.26batch/s, Loss=0.0326, Batch=296/452]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 297/452 [04:19<02:03,  1.25batch/s, Loss=0.0326, Batch=296/452]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 297/452 [04:19<02:03,  1.25batch/s, Loss=0.0325, Batch=297/452]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 298/452 [04:20<02:02,  1.25batch/s, Loss=0.0325, Batch=297/452]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 298/452 [04:20<02:02,  1.25batch/s, Loss=0.0324, Batch=298/452]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 299/452 [04:21<02:01,  1.25batch/s, Loss=0.0324, Batch=298/452]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 299/452 [04:21<02:01,  1.25batch/s, Loss=0.0323, Batch=299/452]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▋   | 300/452 [04:22<02:01,  1.26batch/s, Loss=0.0323, Batch=299/452]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▋   | 300/452 [04:22<02:01,  1.26batch/s, Loss=0.0322, Batch=300/452]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 301/452 [04:22<02:00,  1.26batch/s, Loss=0.0322, Batch=300/452]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 301/452 [04:22<02:00,  1.26batch/s, Loss=0.0321, Batch=301/452]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 302/452 [04:23<01:59,  1.25batch/s, Loss=0.0321, Batch=301/452]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 302/452 [04:23<01:59,  1.25batch/s, Loss=0.0320, Batch=302/452]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 303/452 [04:24<01:58,  1.25batch/s, Loss=0.0320, Batch=302/452]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 303/452 [04:24<01:58,  1.25batch/s, Loss=0.0319, Batch=303/452]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 304/452 [04:25<01:57,  1.26batch/s, Loss=0.0319, Batch=303/452]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 304/452 [04:25<01:57,  1.26batch/s, Loss=0.0318, Batch=304/452]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 305/452 [04:26<01:57,  1.25batch/s, Loss=0.0318, Batch=304/452]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 305/452 [04:26<01:57,  1.25batch/s, Loss=0.0317, Batch=305/452]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 306/452 [04:26<01:56,  1.25batch/s, Loss=0.0317, Batch=305/452]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 306/452 [04:26<01:56,  1.25batch/s, Loss=0.0316, Batch=306/452]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 307/452 [04:27<01:55,  1.26batch/s, Loss=0.0316, Batch=306/452]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 307/452 [04:27<01:55,  1.26batch/s, Loss=0.0315, Batch=307/452]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 308/452 [04:28<01:54,  1.26batch/s, Loss=0.0315, Batch=307/452]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 308/452 [04:28<01:54,  1.26batch/s, Loss=0.0314, Batch=308/452]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 309/452 [04:29<01:53,  1.26batch/s, Loss=0.0314, Batch=308/452]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 309/452 [04:29<01:53,  1.26batch/s, Loss=0.0313, Batch=309/452]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▊   | 310/452 [04:30<01:53,  1.26batch/s, Loss=0.0313, Batch=309/452]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▊   | 310/452 [04:30<01:53,  1.26batch/s, Loss=0.0312, Batch=310/452]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 311/452 [04:30<01:52,  1.26batch/s, Loss=0.0312, Batch=310/452]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 311/452 [04:30<01:52,  1.26batch/s, Loss=0.0311, Batch=311/452]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 312/452 [04:31<01:51,  1.25batch/s, Loss=0.0311, Batch=311/452]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 312/452 [04:31<01:51,  1.25batch/s, Loss=0.0310, Batch=312/452]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 313/452 [04:32<01:51,  1.25batch/s, Loss=0.0310, Batch=312/452]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 313/452 [04:32<01:51,  1.25batch/s, Loss=0.0309, Batch=313/452]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 314/452 [04:33<01:50,  1.25batch/s, Loss=0.0309, Batch=313/452]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 314/452 [04:33<01:50,  1.25batch/s, Loss=0.0308, Batch=314/452]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 315/452 [04:34<01:49,  1.25batch/s, Loss=0.0308, Batch=314/452]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 315/452 [04:34<01:49,  1.25batch/s, Loss=0.0307, Batch=315/452]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 316/452 [04:34<01:48,  1.26batch/s, Loss=0.0307, Batch=315/452]\u001b[A\u001b[A\n",
            "\n",
            " 70%|██████▉   | 316/452 [04:34<01:48,  1.26batch/s, Loss=0.0306, Batch=316/452]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 317/452 [04:35<01:47,  1.26batch/s, Loss=0.0306, Batch=316/452]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 317/452 [04:35<01:47,  1.26batch/s, Loss=0.0305, Batch=317/452]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 318/452 [04:36<01:46,  1.26batch/s, Loss=0.0305, Batch=317/452]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 318/452 [04:36<01:46,  1.26batch/s, Loss=0.0304, Batch=318/452]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 319/452 [04:37<01:45,  1.26batch/s, Loss=0.0304, Batch=318/452]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 319/452 [04:37<01:45,  1.26batch/s, Loss=0.0303, Batch=319/452]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 320/452 [04:38<01:45,  1.25batch/s, Loss=0.0303, Batch=319/452]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 320/452 [04:38<01:45,  1.25batch/s, Loss=0.0302, Batch=320/452]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 321/452 [04:38<01:44,  1.25batch/s, Loss=0.0302, Batch=320/452]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 321/452 [04:38<01:44,  1.25batch/s, Loss=0.0301, Batch=321/452]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 322/452 [04:39<01:43,  1.25batch/s, Loss=0.0301, Batch=321/452]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████   | 322/452 [04:39<01:43,  1.25batch/s, Loss=0.0300, Batch=322/452]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████▏  | 323/452 [04:40<01:42,  1.25batch/s, Loss=0.0300, Batch=322/452]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████▏  | 323/452 [04:40<01:42,  1.25batch/s, Loss=0.0299, Batch=323/452]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 324/452 [04:41<01:41,  1.26batch/s, Loss=0.0299, Batch=323/452]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 324/452 [04:41<01:41,  1.26batch/s, Loss=0.0298, Batch=324/452]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 325/452 [04:42<01:40,  1.26batch/s, Loss=0.0298, Batch=324/452]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 325/452 [04:42<01:40,  1.26batch/s, Loss=0.0297, Batch=325/452]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 326/452 [04:42<01:40,  1.25batch/s, Loss=0.0297, Batch=325/452]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 326/452 [04:42<01:40,  1.25batch/s, Loss=0.0296, Batch=326/452]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 327/452 [04:43<01:39,  1.25batch/s, Loss=0.0296, Batch=326/452]\u001b[A\u001b[A\n",
            "\n",
            " 72%|███████▏  | 327/452 [04:43<01:39,  1.25batch/s, Loss=0.0295, Batch=327/452]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 328/452 [04:44<01:39,  1.25batch/s, Loss=0.0295, Batch=327/452]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 328/452 [04:44<01:39,  1.25batch/s, Loss=0.0294, Batch=328/452]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 329/452 [04:45<01:38,  1.25batch/s, Loss=0.0294, Batch=328/452]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 329/452 [04:45<01:38,  1.25batch/s, Loss=0.0294, Batch=329/452]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 330/452 [04:46<01:37,  1.25batch/s, Loss=0.0294, Batch=329/452]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 330/452 [04:46<01:37,  1.25batch/s, Loss=0.0293, Batch=330/452]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 331/452 [04:46<01:36,  1.25batch/s, Loss=0.0293, Batch=330/452]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 331/452 [04:46<01:36,  1.25batch/s, Loss=0.0292, Batch=331/452]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 332/452 [04:47<01:35,  1.25batch/s, Loss=0.0292, Batch=331/452]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 332/452 [04:47<01:35,  1.25batch/s, Loss=0.0291, Batch=332/452]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▎  | 333/452 [04:48<01:35,  1.25batch/s, Loss=0.0291, Batch=332/452]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▎  | 333/452 [04:48<01:35,  1.25batch/s, Loss=0.0290, Batch=333/452]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 334/452 [04:49<01:34,  1.25batch/s, Loss=0.0290, Batch=333/452]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 334/452 [04:49<01:34,  1.25batch/s, Loss=0.0289, Batch=334/452]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 335/452 [04:50<01:33,  1.25batch/s, Loss=0.0289, Batch=334/452]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 335/452 [04:50<01:33,  1.25batch/s, Loss=0.0288, Batch=335/452]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 336/452 [04:50<01:32,  1.25batch/s, Loss=0.0288, Batch=335/452]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▍  | 336/452 [04:50<01:32,  1.25batch/s, Loss=0.0287, Batch=336/452]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 337/452 [04:51<01:31,  1.25batch/s, Loss=0.0287, Batch=336/452]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 337/452 [04:51<01:31,  1.25batch/s, Loss=0.0287, Batch=337/452]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 338/452 [04:52<01:31,  1.25batch/s, Loss=0.0287, Batch=337/452]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 338/452 [04:52<01:31,  1.25batch/s, Loss=0.0286, Batch=338/452]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 339/452 [04:53<01:30,  1.25batch/s, Loss=0.0286, Batch=338/452]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 339/452 [04:53<01:30,  1.25batch/s, Loss=0.0285, Batch=339/452]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 340/452 [04:54<01:29,  1.25batch/s, Loss=0.0285, Batch=339/452]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 340/452 [04:54<01:29,  1.25batch/s, Loss=0.0284, Batch=340/452]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 341/452 [04:54<01:28,  1.26batch/s, Loss=0.0284, Batch=340/452]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 341/452 [04:54<01:28,  1.26batch/s, Loss=0.0283, Batch=341/452]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 342/452 [04:55<01:27,  1.26batch/s, Loss=0.0283, Batch=341/452]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 342/452 [04:55<01:27,  1.26batch/s, Loss=0.0282, Batch=342/452]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 343/452 [04:56<01:26,  1.26batch/s, Loss=0.0282, Batch=342/452]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 343/452 [04:56<01:26,  1.26batch/s, Loss=0.0282, Batch=343/452]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 344/452 [04:57<01:26,  1.25batch/s, Loss=0.0282, Batch=343/452]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 344/452 [04:57<01:26,  1.25batch/s, Loss=0.0281, Batch=344/452]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▋  | 345/452 [04:58<01:25,  1.25batch/s, Loss=0.0281, Batch=344/452]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▋  | 345/452 [04:58<01:25,  1.25batch/s, Loss=0.0280, Batch=345/452]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 346/452 [04:58<01:24,  1.25batch/s, Loss=0.0280, Batch=345/452]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 346/452 [04:58<01:24,  1.25batch/s, Loss=0.0279, Batch=346/452]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 347/452 [04:59<01:23,  1.25batch/s, Loss=0.0279, Batch=346/452]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 347/452 [04:59<01:23,  1.25batch/s, Loss=0.0278, Batch=347/452]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 348/452 [05:00<01:23,  1.25batch/s, Loss=0.0278, Batch=347/452]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 348/452 [05:00<01:23,  1.25batch/s, Loss=0.0278, Batch=348/452]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 349/452 [05:01<01:22,  1.25batch/s, Loss=0.0278, Batch=348/452]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 349/452 [05:01<01:22,  1.25batch/s, Loss=0.0277, Batch=349/452]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 350/452 [05:02<01:21,  1.25batch/s, Loss=0.0277, Batch=349/452]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 350/452 [05:02<01:21,  1.25batch/s, Loss=0.0276, Batch=350/452]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 351/452 [05:02<01:20,  1.25batch/s, Loss=0.0276, Batch=350/452]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 351/452 [05:02<01:20,  1.25batch/s, Loss=0.0275, Batch=351/452]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 352/452 [05:03<01:19,  1.25batch/s, Loss=0.0275, Batch=351/452]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 352/452 [05:03<01:19,  1.25batch/s, Loss=0.0274, Batch=352/452]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 353/452 [05:04<01:19,  1.25batch/s, Loss=0.0274, Batch=352/452]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 353/452 [05:04<01:19,  1.25batch/s, Loss=0.0274, Batch=353/452]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 354/452 [05:05<01:18,  1.25batch/s, Loss=0.0274, Batch=353/452]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 354/452 [05:05<01:18,  1.25batch/s, Loss=0.0273, Batch=354/452]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▊  | 355/452 [05:06<01:17,  1.25batch/s, Loss=0.0273, Batch=354/452]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▊  | 355/452 [05:06<01:17,  1.25batch/s, Loss=0.0272, Batch=355/452]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 356/452 [05:06<01:16,  1.25batch/s, Loss=0.0272, Batch=355/452]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 356/452 [05:06<01:16,  1.25batch/s, Loss=0.0271, Batch=356/452]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 357/452 [05:07<01:15,  1.25batch/s, Loss=0.0271, Batch=356/452]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 357/452 [05:07<01:15,  1.25batch/s, Loss=0.0271, Batch=357/452]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 358/452 [05:08<01:14,  1.25batch/s, Loss=0.0271, Batch=357/452]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 358/452 [05:08<01:14,  1.25batch/s, Loss=0.0270, Batch=358/452]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 359/452 [05:09<01:14,  1.25batch/s, Loss=0.0270, Batch=358/452]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▉  | 359/452 [05:09<01:14,  1.25batch/s, Loss=0.0269, Batch=359/452]\u001b[A\u001b[A\n",
            "\n",
            " 80%|███████▉  | 360/452 [05:10<01:13,  1.25batch/s, Loss=0.0269, Batch=359/452]\u001b[A\u001b[A\n",
            "\n",
            " 80%|███████▉  | 360/452 [05:10<01:13,  1.25batch/s, Loss=0.0268, Batch=360/452]\u001b[A\u001b[A\n",
            "\n",
            " 80%|███████▉  | 361/452 [05:10<01:12,  1.25batch/s, Loss=0.0268, Batch=360/452]\u001b[A\u001b[A\n",
            "\n",
            " 80%|███████▉  | 361/452 [05:10<01:12,  1.25batch/s, Loss=0.0268, Batch=361/452]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 362/452 [05:11<01:11,  1.26batch/s, Loss=0.0268, Batch=361/452]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 362/452 [05:11<01:11,  1.26batch/s, Loss=0.0267, Batch=362/452]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 363/452 [05:12<01:10,  1.26batch/s, Loss=0.0267, Batch=362/452]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 363/452 [05:12<01:10,  1.26batch/s, Loss=0.0266, Batch=363/452]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 364/452 [05:13<01:10,  1.26batch/s, Loss=0.0266, Batch=363/452]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 364/452 [05:13<01:10,  1.26batch/s, Loss=0.0265, Batch=364/452]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 365/452 [05:14<01:09,  1.26batch/s, Loss=0.0265, Batch=364/452]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 365/452 [05:14<01:09,  1.26batch/s, Loss=0.0265, Batch=365/452]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 366/452 [05:14<01:08,  1.26batch/s, Loss=0.0265, Batch=365/452]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 366/452 [05:14<01:08,  1.26batch/s, Loss=0.0264, Batch=366/452]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 367/452 [05:15<01:07,  1.25batch/s, Loss=0.0264, Batch=366/452]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 367/452 [05:15<01:07,  1.25batch/s, Loss=0.0263, Batch=367/452]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████▏ | 368/452 [05:16<01:07,  1.25batch/s, Loss=0.0263, Batch=367/452]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████▏ | 368/452 [05:16<01:07,  1.25batch/s, Loss=0.0263, Batch=368/452]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 369/452 [05:17<01:06,  1.25batch/s, Loss=0.0263, Batch=368/452]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 369/452 [05:17<01:06,  1.25batch/s, Loss=0.0262, Batch=369/452]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 370/452 [05:17<01:05,  1.26batch/s, Loss=0.0262, Batch=369/452]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 370/452 [05:17<01:05,  1.26batch/s, Loss=0.0261, Batch=370/452]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 371/452 [05:18<01:04,  1.25batch/s, Loss=0.0261, Batch=370/452]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 371/452 [05:18<01:04,  1.25batch/s, Loss=0.0260, Batch=371/452]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 372/452 [05:19<01:03,  1.25batch/s, Loss=0.0260, Batch=371/452]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 372/452 [05:19<01:03,  1.25batch/s, Loss=0.0260, Batch=372/452]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 373/452 [05:20<01:03,  1.25batch/s, Loss=0.0260, Batch=372/452]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 373/452 [05:20<01:03,  1.25batch/s, Loss=0.0259, Batch=373/452]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 374/452 [05:21<01:02,  1.25batch/s, Loss=0.0259, Batch=373/452]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 374/452 [05:21<01:02,  1.25batch/s, Loss=0.0258, Batch=374/452]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 375/452 [05:21<01:01,  1.25batch/s, Loss=0.0258, Batch=374/452]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 375/452 [05:21<01:01,  1.25batch/s, Loss=0.0258, Batch=375/452]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 376/452 [05:22<01:00,  1.25batch/s, Loss=0.0258, Batch=375/452]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 376/452 [05:22<01:00,  1.25batch/s, Loss=0.0257, Batch=376/452]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 377/452 [05:23<00:59,  1.25batch/s, Loss=0.0257, Batch=376/452]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 377/452 [05:23<00:59,  1.25batch/s, Loss=0.0256, Batch=377/452]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▎ | 378/452 [05:24<00:59,  1.25batch/s, Loss=0.0256, Batch=377/452]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▎ | 378/452 [05:24<00:59,  1.25batch/s, Loss=0.0256, Batch=378/452]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 379/452 [05:25<00:58,  1.25batch/s, Loss=0.0256, Batch=378/452]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 379/452 [05:25<00:58,  1.25batch/s, Loss=0.0255, Batch=379/452]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 380/452 [05:25<00:57,  1.25batch/s, Loss=0.0255, Batch=379/452]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 380/452 [05:25<00:57,  1.25batch/s, Loss=0.0254, Batch=380/452]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 381/452 [05:26<00:56,  1.25batch/s, Loss=0.0254, Batch=380/452]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 381/452 [05:26<00:56,  1.25batch/s, Loss=0.0254, Batch=381/452]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 382/452 [05:27<00:55,  1.25batch/s, Loss=0.0254, Batch=381/452]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 382/452 [05:27<00:55,  1.25batch/s, Loss=0.0253, Batch=382/452]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 383/452 [05:28<00:54,  1.26batch/s, Loss=0.0253, Batch=382/452]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 383/452 [05:28<00:54,  1.26batch/s, Loss=0.0252, Batch=383/452]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 384/452 [05:29<00:54,  1.26batch/s, Loss=0.0252, Batch=383/452]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▍ | 384/452 [05:29<00:54,  1.26batch/s, Loss=0.0252, Batch=384/452]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 385/452 [05:29<00:53,  1.26batch/s, Loss=0.0252, Batch=384/452]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 385/452 [05:29<00:53,  1.26batch/s, Loss=0.0251, Batch=385/452]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 386/452 [05:30<00:52,  1.26batch/s, Loss=0.0251, Batch=385/452]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 386/452 [05:30<00:52,  1.26batch/s, Loss=0.0250, Batch=386/452]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 387/452 [05:31<00:51,  1.25batch/s, Loss=0.0250, Batch=386/452]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 387/452 [05:31<00:51,  1.25batch/s, Loss=0.0250, Batch=387/452]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 388/452 [05:32<00:51,  1.25batch/s, Loss=0.0250, Batch=387/452]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 388/452 [05:32<00:51,  1.25batch/s, Loss=0.0249, Batch=388/452]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 389/452 [05:33<00:50,  1.25batch/s, Loss=0.0249, Batch=388/452]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 389/452 [05:33<00:50,  1.25batch/s, Loss=0.0248, Batch=389/452]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▋ | 390/452 [05:33<00:49,  1.25batch/s, Loss=0.0248, Batch=389/452]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▋ | 390/452 [05:33<00:49,  1.25batch/s, Loss=0.0248, Batch=390/452]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 391/452 [05:34<00:48,  1.25batch/s, Loss=0.0248, Batch=390/452]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 391/452 [05:34<00:48,  1.25batch/s, Loss=0.0247, Batch=391/452]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 392/452 [05:35<00:47,  1.25batch/s, Loss=0.0247, Batch=391/452]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 392/452 [05:35<00:47,  1.25batch/s, Loss=0.0246, Batch=392/452]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 393/452 [05:36<00:47,  1.25batch/s, Loss=0.0246, Batch=392/452]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 393/452 [05:36<00:47,  1.25batch/s, Loss=0.0246, Batch=393/452]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 394/452 [05:37<00:46,  1.25batch/s, Loss=0.0246, Batch=393/452]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 394/452 [05:37<00:46,  1.25batch/s, Loss=0.0245, Batch=394/452]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 395/452 [05:37<00:45,  1.25batch/s, Loss=0.0245, Batch=394/452]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 395/452 [05:37<00:45,  1.25batch/s, Loss=0.0245, Batch=395/452]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 396/452 [05:38<00:44,  1.25batch/s, Loss=0.0245, Batch=395/452]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 396/452 [05:38<00:44,  1.25batch/s, Loss=0.0244, Batch=396/452]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 397/452 [05:39<00:43,  1.25batch/s, Loss=0.0244, Batch=396/452]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 397/452 [05:39<00:43,  1.25batch/s, Loss=0.0243, Batch=397/452]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 398/452 [05:40<00:43,  1.25batch/s, Loss=0.0243, Batch=397/452]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 398/452 [05:40<00:43,  1.25batch/s, Loss=0.0243, Batch=398/452]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 399/452 [05:41<00:42,  1.25batch/s, Loss=0.0243, Batch=398/452]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 399/452 [05:41<00:42,  1.25batch/s, Loss=0.0242, Batch=399/452]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 400/452 [05:41<00:41,  1.26batch/s, Loss=0.0242, Batch=399/452]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 400/452 [05:41<00:41,  1.26batch/s, Loss=0.0242, Batch=400/452]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▊ | 401/452 [05:42<00:40,  1.26batch/s, Loss=0.0242, Batch=400/452]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▊ | 401/452 [05:42<00:40,  1.26batch/s, Loss=0.0241, Batch=401/452]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 402/452 [05:43<00:39,  1.25batch/s, Loss=0.0241, Batch=401/452]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 402/452 [05:43<00:39,  1.25batch/s, Loss=0.0240, Batch=402/452]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 403/452 [05:44<00:39,  1.26batch/s, Loss=0.0240, Batch=402/452]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 403/452 [05:44<00:39,  1.26batch/s, Loss=0.0240, Batch=403/452]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 404/452 [05:45<00:38,  1.26batch/s, Loss=0.0240, Batch=403/452]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 404/452 [05:45<00:38,  1.26batch/s, Loss=0.0239, Batch=404/452]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 405/452 [05:45<00:37,  1.26batch/s, Loss=0.0239, Batch=404/452]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 405/452 [05:45<00:37,  1.26batch/s, Loss=0.0239, Batch=405/452]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 406/452 [05:46<00:36,  1.26batch/s, Loss=0.0239, Batch=405/452]\u001b[A\u001b[A\n",
            "\n",
            " 90%|████████▉ | 406/452 [05:46<00:36,  1.26batch/s, Loss=0.0238, Batch=406/452]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 407/452 [05:47<00:35,  1.26batch/s, Loss=0.0238, Batch=406/452]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 407/452 [05:47<00:35,  1.26batch/s, Loss=0.0237, Batch=407/452]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 408/452 [05:48<00:34,  1.26batch/s, Loss=0.0237, Batch=407/452]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 408/452 [05:48<00:34,  1.26batch/s, Loss=0.0237, Batch=408/452]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 409/452 [05:49<00:34,  1.26batch/s, Loss=0.0237, Batch=408/452]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 409/452 [05:49<00:34,  1.26batch/s, Loss=0.0236, Batch=409/452]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 410/452 [05:49<00:33,  1.26batch/s, Loss=0.0236, Batch=409/452]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 410/452 [05:49<00:33,  1.26batch/s, Loss=0.0236, Batch=410/452]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 411/452 [05:50<00:32,  1.26batch/s, Loss=0.0236, Batch=410/452]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 411/452 [05:50<00:32,  1.26batch/s, Loss=0.0235, Batch=411/452]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 412/452 [05:51<00:31,  1.26batch/s, Loss=0.0235, Batch=411/452]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████ | 412/452 [05:51<00:31,  1.26batch/s, Loss=0.0234, Batch=412/452]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████▏| 413/452 [05:52<00:31,  1.26batch/s, Loss=0.0234, Batch=412/452]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████▏| 413/452 [05:52<00:31,  1.26batch/s, Loss=0.0234, Batch=413/452]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 414/452 [05:53<00:30,  1.26batch/s, Loss=0.0234, Batch=413/452]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 414/452 [05:53<00:30,  1.26batch/s, Loss=0.0233, Batch=414/452]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 415/452 [05:53<00:29,  1.26batch/s, Loss=0.0233, Batch=414/452]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 415/452 [05:53<00:29,  1.26batch/s, Loss=0.0233, Batch=415/452]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 416/452 [05:54<00:28,  1.25batch/s, Loss=0.0233, Batch=415/452]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 416/452 [05:54<00:28,  1.25batch/s, Loss=0.0232, Batch=416/452]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 417/452 [05:55<00:27,  1.26batch/s, Loss=0.0232, Batch=416/452]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 417/452 [05:55<00:27,  1.26batch/s, Loss=0.0232, Batch=417/452]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 418/452 [05:56<00:27,  1.25batch/s, Loss=0.0232, Batch=417/452]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 418/452 [05:56<00:27,  1.25batch/s, Loss=0.0231, Batch=418/452]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 419/452 [05:57<00:26,  1.25batch/s, Loss=0.0231, Batch=418/452]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 419/452 [05:57<00:26,  1.25batch/s, Loss=0.0231, Batch=419/452]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 420/452 [05:57<00:25,  1.26batch/s, Loss=0.0231, Batch=419/452]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 420/452 [05:57<00:25,  1.26batch/s, Loss=0.0230, Batch=420/452]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 421/452 [05:58<00:24,  1.24batch/s, Loss=0.0230, Batch=420/452]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 421/452 [05:58<00:24,  1.24batch/s, Loss=0.0229, Batch=421/452]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 422/452 [05:59<00:24,  1.25batch/s, Loss=0.0229, Batch=421/452]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 422/452 [05:59<00:24,  1.25batch/s, Loss=0.0229, Batch=422/452]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▎| 423/452 [06:00<00:23,  1.25batch/s, Loss=0.0229, Batch=422/452]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▎| 423/452 [06:00<00:23,  1.25batch/s, Loss=0.0228, Batch=423/452]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 424/452 [06:01<00:22,  1.25batch/s, Loss=0.0228, Batch=423/452]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 424/452 [06:01<00:22,  1.25batch/s, Loss=0.0228, Batch=424/452]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 425/452 [06:01<00:21,  1.25batch/s, Loss=0.0228, Batch=424/452]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 425/452 [06:01<00:21,  1.25batch/s, Loss=0.0227, Batch=425/452]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 426/452 [06:02<00:20,  1.25batch/s, Loss=0.0227, Batch=425/452]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 426/452 [06:02<00:20,  1.25batch/s, Loss=0.0227, Batch=426/452]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 427/452 [06:03<00:20,  1.25batch/s, Loss=0.0227, Batch=426/452]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 427/452 [06:03<00:20,  1.25batch/s, Loss=0.0226, Batch=427/452]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 428/452 [06:04<00:19,  1.25batch/s, Loss=0.0226, Batch=427/452]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 428/452 [06:04<00:19,  1.25batch/s, Loss=0.0226, Batch=428/452]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 429/452 [06:05<00:18,  1.25batch/s, Loss=0.0226, Batch=428/452]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▍| 429/452 [06:05<00:18,  1.25batch/s, Loss=0.0225, Batch=429/452]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 430/452 [06:05<00:17,  1.25batch/s, Loss=0.0225, Batch=429/452]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 430/452 [06:05<00:17,  1.25batch/s, Loss=0.0225, Batch=430/452]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 431/452 [06:06<00:16,  1.25batch/s, Loss=0.0225, Batch=430/452]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 431/452 [06:06<00:16,  1.25batch/s, Loss=0.0224, Batch=431/452]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 432/452 [06:07<00:16,  1.24batch/s, Loss=0.0224, Batch=431/452]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 432/452 [06:07<00:16,  1.24batch/s, Loss=0.0224, Batch=432/452]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 433/452 [06:08<00:15,  1.24batch/s, Loss=0.0224, Batch=432/452]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 433/452 [06:08<00:15,  1.24batch/s, Loss=0.0223, Batch=433/452]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 434/452 [06:09<00:14,  1.24batch/s, Loss=0.0223, Batch=433/452]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 434/452 [06:09<00:14,  1.24batch/s, Loss=0.0223, Batch=434/452]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 435/452 [06:09<00:13,  1.24batch/s, Loss=0.0223, Batch=434/452]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 435/452 [06:09<00:13,  1.24batch/s, Loss=0.0222, Batch=435/452]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▋| 436/452 [06:10<00:12,  1.24batch/s, Loss=0.0222, Batch=435/452]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▋| 436/452 [06:10<00:12,  1.24batch/s, Loss=0.0222, Batch=436/452]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 437/452 [06:11<00:12,  1.24batch/s, Loss=0.0222, Batch=436/452]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 437/452 [06:11<00:12,  1.24batch/s, Loss=0.0221, Batch=437/452]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 438/452 [06:12<00:11,  1.24batch/s, Loss=0.0221, Batch=437/452]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 438/452 [06:12<00:11,  1.24batch/s, Loss=0.0221, Batch=438/452]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 439/452 [06:13<00:10,  1.24batch/s, Loss=0.0221, Batch=438/452]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 439/452 [06:13<00:10,  1.24batch/s, Loss=0.0220, Batch=439/452]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 440/452 [06:13<00:09,  1.24batch/s, Loss=0.0220, Batch=439/452]\u001b[A\u001b[A\n",
            "\n",
            " 97%|█████████▋| 440/452 [06:13<00:09,  1.24batch/s, Loss=0.0220, Batch=440/452]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 441/452 [06:14<00:08,  1.24batch/s, Loss=0.0220, Batch=440/452]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 441/452 [06:14<00:08,  1.24batch/s, Loss=0.0219, Batch=441/452]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 442/452 [06:15<00:08,  1.24batch/s, Loss=0.0219, Batch=441/452]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 442/452 [06:15<00:08,  1.24batch/s, Loss=0.0219, Batch=442/452]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 443/452 [06:16<00:07,  1.25batch/s, Loss=0.0219, Batch=442/452]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 443/452 [06:16<00:07,  1.25batch/s, Loss=0.0218, Batch=443/452]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 444/452 [06:17<00:06,  1.25batch/s, Loss=0.0218, Batch=443/452]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 444/452 [06:17<00:06,  1.25batch/s, Loss=0.0218, Batch=444/452]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 445/452 [06:17<00:05,  1.25batch/s, Loss=0.0218, Batch=444/452]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 445/452 [06:17<00:05,  1.25batch/s, Loss=0.0217, Batch=445/452]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▊| 446/452 [06:18<00:04,  1.25batch/s, Loss=0.0217, Batch=445/452]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▊| 446/452 [06:18<00:04,  1.25batch/s, Loss=0.0217, Batch=446/452]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 447/452 [06:19<00:04,  1.25batch/s, Loss=0.0217, Batch=446/452]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 447/452 [06:19<00:04,  1.25batch/s, Loss=0.0216, Batch=447/452]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 448/452 [06:20<00:03,  1.25batch/s, Loss=0.0216, Batch=447/452]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 448/452 [06:20<00:03,  1.25batch/s, Loss=0.0216, Batch=448/452]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 449/452 [06:21<00:02,  1.25batch/s, Loss=0.0216, Batch=448/452]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▉| 449/452 [06:21<00:02,  1.25batch/s, Loss=0.0215, Batch=449/452]\u001b[A\u001b[A\n",
            "\n",
            "100%|█████████▉| 450/452 [06:21<00:01,  1.25batch/s, Loss=0.0215, Batch=449/452]\u001b[A\u001b[A\n",
            "\n",
            "100%|█████████▉| 450/452 [06:21<00:01,  1.25batch/s, Loss=0.0215, Batch=450/452]\u001b[A\u001b[A\n",
            "\n",
            "100%|█████████▉| 451/452 [06:22<00:00,  1.25batch/s, Loss=0.0215, Batch=450/452]\u001b[A\u001b[A\n",
            "\n",
            "100%|█████████▉| 451/452 [06:22<00:00,  1.25batch/s, Loss=0.0214, Batch=451/452]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 452/452 [06:22<00:00,  1.58batch/s, Loss=0.0214, Batch=451/452]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 452/452 [06:23<00:00,  1.18batch/s, Loss=0.0214, Batch=452/452]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Average Loss: 0.0214\n",
            "\n",
            "Epoch [2/100]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 409/452 [05:25<00:34,  1.26batch/s, Loss=0.0000, Batch=409/452]"
          ]
        }
      ],
      "source": [
        "def run_pipeline():\n",
        "    \"\"\"Main pipeline with results saving and visualization\"\"\"\n",
        "    try:\n",
        "        print(\"Starting pipeline...\")\n",
        "\n",
        "        # Initialize data manager\n",
        "        data_manager = DataManager(Config)\n",
        "        file_list = Config.get_file_list()\n",
        "\n",
        "        if not file_list:\n",
        "            raise ValueError(\"No data files found in specified directory\")\n",
        "\n",
        "        df = data_manager.load_data(file_list)\n",
        "\n",
        "        # Convert dates\n",
        "        train_start = pd.to_datetime(Config.TRAIN_START_DATE, utc=True)\n",
        "        train_end = pd.to_datetime(Config.TRAIN_END_DATE, utc=True)\n",
        "        test_start = pd.to_datetime(Config.TEST_START_DATE, utc=True)\n",
        "        test_end = pd.to_datetime(Config.TEST_END_DATE, utc=True)\n",
        "\n",
        "        # Preprocess data\n",
        "        X_train, y_train, X_test, y_test, scaler, test_df = data_manager.preprocess_data(\n",
        "            df, train_start, train_end, test_start, test_end, Config.SEQUENCE_LENGTH\n",
        "        )\n",
        "\n",
        "        # Save scaler for future use\n",
        "        scaler_path = os.path.join(Config.RESULTS_DIR, 'scaler.pkl')\n",
        "        with open(scaler_path, 'wb') as f:\n",
        "            pickle.dump(scaler, f)\n",
        "\n",
        "        # Initialize model\n",
        "        model = LSTMModel(hidden_size=Config.HIDDEN_SIZE, num_layers=Config.NUM_LAYERS).to(device)\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)\n",
        "\n",
        "        # Train model\n",
        "        train_model_with_progress(model, X_train, y_train, criterion, optimizer)\n",
        "\n",
        "        # Generate predictions\n",
        "        test_predictions = predict_with_progress(model, X_test, scaler)\n",
        "\n",
        "        # Create and save predictions DataFrame\n",
        "        predictions_df = pd.DataFrame({\n",
        "            'ts_event': test_df['ts_event'][Config.SEQUENCE_LENGTH:].reset_index(drop=True),\n",
        "            'predicted_price': test_predictions,\n",
        "            'actual_price': test_df['price'][Config.SEQUENCE_LENGTH:].reset_index(drop=True)\n",
        "        })\n",
        "\n",
        "        # Save predictions\n",
        "        predictions_path = os.path.join(Config.RESULTS_DIR, 'predictions.csv')\n",
        "        predictions_df.to_csv(predictions_path, index=False)\n",
        "\n",
        "        # Generate and save visualizations\n",
        "        print(\"\\nGenerating visualizations...\")\n",
        "\n",
        "        # Create main visualization\n",
        "        fig1 = visualize_predictions(predictions_df)\n",
        "        fig1_path = os.path.join(Config.RESULTS_DIR, 'prediction_analysis.png')\n",
        "        fig1.savefig(fig1_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close(fig1)\n",
        "\n",
        "        # Create error analysis visualization\n",
        "        fig2 = plot_error_analysis(predictions_df)\n",
        "        fig2_path = os.path.join(Config.RESULTS_DIR, 'error_analysis.png')\n",
        "        fig2.savefig(fig2_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close(fig2)\n",
        "\n",
        "        # Save model configuration\n",
        "        config_path = os.path.join(Config.RESULTS_DIR, 'model_config.json')\n",
        "        config_dict = {\n",
        "            'HIDDEN_SIZE': Config.HIDDEN_SIZE,\n",
        "            'NUM_LAYERS': Config.NUM_LAYERS,\n",
        "            'SEQUENCE_LENGTH': Config.SEQUENCE_LENGTH,\n",
        "            'LEARNING_RATE': Config.LEARNING_RATE,\n",
        "            'TRAIN_START_DATE': Config.TRAIN_START_DATE,\n",
        "            'TRAIN_END_DATE': Config.TRAIN_END_DATE,\n",
        "            'TEST_START_DATE': Config.TEST_START_DATE,\n",
        "            'TEST_END_DATE': Config.TEST_END_DATE\n",
        "        }\n",
        "        with open(config_path, 'w') as f:\n",
        "            json.dump(config_dict, f, indent=4)\n",
        "\n",
        "        print(f\"\\nResults saved in: {Config.RESULTS_DIR}\")\n",
        "        print(f\"Model checkpoints saved in: {os.path.join(Config.RESULTS_DIR, 'models')}\")\n",
        "        print(f\"Visualizations saved as:\")\n",
        "        print(f\"- {fig1_path}\")\n",
        "        print(f\"- {fig2_path}\")\n",
        "\n",
        "        # Display visualizations in notebook\n",
        "        plt.figure(figsize=(20, 15))\n",
        "        visualize_predictions(predictions_df)\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(20, 10))\n",
        "        plot_error_analysis(predictions_df)\n",
        "        plt.show()\n",
        "\n",
        "        return predictions_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in pipeline: {str(e)}\")\n",
        "        raise e\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Clear any existing cached memory\n",
        "    torch.cuda.empty_cache()\n",
        "    predictions_df = run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def check_gpu_memory():\n",
        "    \"\"\"\n",
        "    Check and display detailed GPU memory usage.\n",
        "\n",
        "    Returns:\n",
        "        dict: Memory statistics in GB\n",
        "    \"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"No GPU available!\")\n",
        "        return None\n",
        "\n",
        "    # Get memory statistics in GB\n",
        "    total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "    reserved = torch.cuda.memory_reserved(0) / (1024**3)\n",
        "    allocated = torch.cuda.memory_allocated(0) / (1024**3)\n",
        "    free = total - reserved\n",
        "\n",
        "    # Print memory status\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"GPU Memory Status ({torch.cuda.get_device_name(0)})\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Total GPU Memory:     {total:.2f} GB\")\n",
        "    print(f\"Reserved Memory:      {reserved:.2f} GB\")\n",
        "    print(f\"Allocated Memory:     {allocated:.2f} GB\")\n",
        "    print(f\"Free Memory:          {free:.2f} GB\")\n",
        "    print(f\"Memory Utilization:   {(reserved/total)*100:.1f}%\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    return {\n",
        "        \"total\": round(total, 2),\n",
        "        \"reserved\": round(reserved, 2),\n",
        "        \"allocated\": round(allocated, 2),\n",
        "        \"free\": round(free, 2),\n",
        "        \"utilization\": round((reserved/total)*100, 1)\n",
        "    }\n",
        "\n",
        "# Actually run the function to see the output\n",
        "memory_stats = check_gpu_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abQ_aqgquZy-",
        "outputId": "d82f6ad1-1bd7-415e-a56f-e0be9abb9c09"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "GPU Memory Status (NVIDIA A100-SXM4-40GB)\n",
            "==================================================\n",
            "Total GPU Memory:     39.56 GB\n",
            "Reserved Memory:      1.75 GB\n",
            "Allocated Memory:     1.73 GB\n",
            "Free Memory:          37.81 GB\n",
            "Memory Utilization:   4.4%\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uUN_A5X04TkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "import os\n",
        "import logging\n",
        "from typing import Optional, Dict\n",
        "\n",
        "class GPUMemoryManager:\n",
        "    def __init__(self, threshold_gb: float = 5.0, debug: bool = True):\n",
        "        \"\"\"\n",
        "        Initialize the GPU Memory Manager\n",
        "\n",
        "        Args:\n",
        "            threshold_gb (float): Minimum free memory threshold in GB to trigger cleanup\n",
        "            debug (bool): Whether to print detailed memory information\n",
        "        \"\"\"\n",
        "        self.threshold_gb = threshold_gb\n",
        "        self.debug = debug\n",
        "        self.setup_logging()\n",
        "\n",
        "        # Set PyTorch memory allocation settings\n",
        "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = (\n",
        "            'max_split_size_mb:512,'\n",
        "            'expandable_segments:True,'\n",
        "            'garbage_collection_threshold:0.8'\n",
        "        )\n",
        "\n",
        "    def setup_logging(self):\n",
        "        \"\"\"Setup logging configuration\"\"\"\n",
        "        logging.basicConfig(\n",
        "            level=logging.DEBUG if self.debug else logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def get_gpu_memory_info(self) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Get detailed GPU memory information using PyTorch\n",
        "\n",
        "        Returns:\n",
        "            Dict containing memory information in GB\n",
        "        \"\"\"\n",
        "        if not torch.cuda.is_available():\n",
        "            return {\"error\": \"CUDA not available\"}\n",
        "\n",
        "        try:\n",
        "            # Get memory information from PyTorch\n",
        "            allocated = torch.cuda.memory_allocated() / 1e9  # Convert to GB\n",
        "            reserved = torch.cuda.memory_reserved() / 1e9\n",
        "            max_memory = torch.cuda.max_memory_allocated() / 1e9\n",
        "\n",
        "            # Calculate total GPU memory\n",
        "            total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "            free = total - allocated\n",
        "\n",
        "            return {\n",
        "                \"total_memory_gb\": total,\n",
        "                \"free_memory_gb\": free,\n",
        "                \"used_memory_gb\": allocated,\n",
        "                \"allocated_memory_gb\": allocated,\n",
        "                \"reserved_memory_gb\": reserved,\n",
        "                \"max_allocated_gb\": max_memory,\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error getting GPU memory info: {str(e)}\")\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def print_memory_stats(self):\n",
        "        \"\"\"Print detailed memory statistics\"\"\"\n",
        "        memory_info = self.get_gpu_memory_info()\n",
        "\n",
        "        if \"error\" in memory_info:\n",
        "            self.logger.error(f\"Could not get memory stats: {memory_info['error']}\")\n",
        "            return\n",
        "\n",
        "        self.logger.info(\"\\n=== GPU Memory Statistics ===\")\n",
        "        self.logger.info(f\"Total GPU Memory: {memory_info['total_memory_gb']:.2f} GB\")\n",
        "        self.logger.info(f\"Free GPU Memory: {memory_info['free_memory_gb']:.2f} GB\")\n",
        "        self.logger.info(f\"Used GPU Memory: {memory_info['used_memory_gb']:.2f} GB\")\n",
        "        self.logger.info(f\"Allocated by PyTorch: {memory_info['allocated_memory_gb']:.2f} GB\")\n",
        "        self.logger.info(f\"Reserved by PyTorch: {memory_info['reserved_memory_gb']:.2f} GB\")\n",
        "        self.logger.info(f\"Max Allocated: {memory_info['max_allocated_gb']:.2f} GB\")\n",
        "        self.logger.info(\"===========================\\n\")\n",
        "\n",
        "    def clear_memory(self, force: bool = False) -> bool:\n",
        "        \"\"\"\n",
        "        Clear GPU memory if usage is above threshold or if forced\n",
        "\n",
        "        Args:\n",
        "            force (bool): Force memory cleanup regardless of threshold\n",
        "\n",
        "        Returns:\n",
        "            bool: True if cleanup was performed, False otherwise\n",
        "        \"\"\"\n",
        "        if not torch.cuda.is_available():\n",
        "            self.logger.warning(\"CUDA not available\")\n",
        "            return False\n",
        "\n",
        "        memory_info = self.get_gpu_memory_info()\n",
        "\n",
        "        if \"error\" in memory_info:\n",
        "            self.logger.error(f\"Could not clear memory: {memory_info['error']}\")\n",
        "            return False\n",
        "\n",
        "        if force or memory_info['free_memory_gb'] < self.threshold_gb:\n",
        "            try:\n",
        "                # Print initial state if debugging\n",
        "                if self.debug:\n",
        "                    self.logger.info(\"Before cleanup:\")\n",
        "                    self.print_memory_stats()\n",
        "\n",
        "                # Clear CUDA cache\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                # Run garbage collector\n",
        "                gc.collect()\n",
        "\n",
        "                # Clear peak memory stats\n",
        "                torch.cuda.reset_peak_memory_stats()\n",
        "                if hasattr(torch.cuda, 'reset_accumulated_memory_stats'):\n",
        "                    torch.cuda.reset_accumulated_memory_stats()\n",
        "\n",
        "                # Delete any remaining CUDA tensors\n",
        "                for obj in gc.get_objects():\n",
        "                    try:\n",
        "                        if torch.is_tensor(obj):\n",
        "                            if obj.is_cuda:\n",
        "                                del obj\n",
        "                    except Exception:\n",
        "                        pass\n",
        "\n",
        "                # Run garbage collector again\n",
        "                gc.collect()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                # Print final state if debugging\n",
        "                if self.debug:\n",
        "                    self.logger.info(\"After cleanup:\")\n",
        "                    self.print_memory_stats()\n",
        "\n",
        "                return True\n",
        "\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error during memory cleanup: {str(e)}\")\n",
        "                return False\n",
        "\n",
        "        return False\n",
        "\n",
        "    def get_memory_fragmentation(self) -> Optional[float]:\n",
        "        \"\"\"\n",
        "        Calculate memory fragmentation ratio\n",
        "\n",
        "        Returns:\n",
        "            float: Fragmentation ratio (0-1) or None if calculation fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            memory_info = self.get_gpu_memory_info()\n",
        "            if \"error\" in memory_info:\n",
        "                return None\n",
        "\n",
        "            allocated = memory_info['allocated_memory_gb']\n",
        "            reserved = memory_info['reserved_memory_gb']\n",
        "\n",
        "            if reserved == 0:\n",
        "                return 0.0\n",
        "\n",
        "            return 1.0 - (allocated / reserved)\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error calculating fragmentation: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def is_memory_critical(self) -> bool:\n",
        "        \"\"\"\n",
        "        Check if memory usage is in a critical state\n",
        "\n",
        "        Returns:\n",
        "            bool: True if memory usage is critical\n",
        "        \"\"\"\n",
        "        memory_info = self.get_gpu_memory_info()\n",
        "\n",
        "        if \"error\" in memory_info:\n",
        "            return True\n",
        "\n",
        "        free_memory = memory_info['free_memory_gb']\n",
        "        total_memory = memory_info['total_memory_gb']\n",
        "\n",
        "        # Consider memory critical if less than 10% free\n",
        "        return free_memory < (total_memory * 0.1)\n",
        "\n",
        "def quick_memory_cleanup():\n",
        "    \"\"\"\n",
        "    Quick function to clear GPU memory without creating a manager instance\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        # Clear CUDA cache\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Run garbage collector\n",
        "        gc.collect()\n",
        "\n",
        "        # Reset memory stats\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "        # Delete CUDA tensors\n",
        "        for obj in gc.get_objects():\n",
        "            try:\n",
        "                if torch.is_tensor(obj):\n",
        "                    if obj.is_cuda:\n",
        "                        del obj\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Final cleanup\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Option 1: Using the full manager\n",
        "    memory_manager = GPUMemoryManager(threshold_gb=5.0, debug=True)\n",
        "    memory_manager.print_memory_stats()\n",
        "    memory_manager.clear_memory(force=True)\n",
        "\n",
        "    # Option 2: Quick cleanup\n",
        "    quick_memory_cleanup()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJtZJMidxx6s",
        "outputId": "05a2818b-4dc0-45e7-d4d1-9c789c6b3f12"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1022: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  return isinstance(obj, torch.Tensor)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUiWr41zq5qZ"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize config\n",
        "    Config.initialize()\n",
        "\n",
        "    # Get file list\n",
        "    file_list = Config.get_file_list()\n",
        "\n",
        "    # Load data\n",
        "    df = load_csv_data(file_list)\n",
        "\n",
        "    # Preprocess data\n",
        "    train_start = pd.to_datetime(Config.TRAIN_START_DATE, utc=True)\n",
        "    train_end = pd.to_datetime(Config.TRAIN_END_DATE, utc=True)\n",
        "    test_start = pd.to_datetime(Config.TEST_START_DATE, utc=True)\n",
        "    test_end = pd.to_datetime(Config.TEST_END_DATE, utc=True)\n",
        "\n",
        "    # Plot training data\n",
        "    plot_train_data(df, train_start, train_end)\n",
        "\n",
        "    X_train, y_train, X_test, y_test, scaler, test_df = preprocess_data(\n",
        "        df, train_start, train_end, test_start, test_end, Config.SEQUENCE_LENGTH\n",
        "    )\n",
        "\n",
        "    # Create dataset and dataloader for training data\n",
        "    train_dataset = PriceDataset(X_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=Config.NUM_WORKERS)\n",
        "    \n",
        "    # Initialize model, loss function, and optimizer\n",
        "    model = LSTMModel(hidden_size=Config.HIDDEN_SIZE, num_layers=Config.NUM_LAYERS)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)\n",
        "    \n",
        "    # Train the model\n",
        "    train_model_with_progress(model, train_loader, criterion, optimizer)\n",
        "    \n",
        "    # Make predictions on test data\n",
        "    test_predictions = predict_with_progress(model, X_test, scaler)\n",
        "    \n",
        "    # Create a DataFrame with test predictions\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'ts_event': test_df['ts_event'][Config.SEQUENCE_LENGTH:].reset_index(drop=True),\n",
        "        'predicted_price': test_predictions,\n",
        "        'actual_price': test_df['price'][Config.SEQUENCE_LENGTH:].reset_index(drop=True)\n",
        "    })\n",
        "    \n",
        "    # Plot predicted vs actual prices for test data\n",
        "    plot_predicted_vs_actual(predictions_df, test_start, test_end)\n",
        "    \n",
        "    print(predictions_df)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}